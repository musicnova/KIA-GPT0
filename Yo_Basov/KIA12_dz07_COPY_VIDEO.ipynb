{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ЧЕРНОВОЙ ВАРИАНТ добавляет разделы video в раздел # section-3 и нейро копирайтером опиcывает структуру разделов\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QysPyVsSqKxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"config.txt\", \"w\") as fw:\n",
        "    fw.write(\"[COLAB]\\n\")\n",
        "    fw.write(\"knowledge_dir=/content/drive/MyDrive/KIA_AVATAR/Scripts/knowledge\\n\")\n",
        "    fw.write(\"prev_knowledge_dir=/content/drive/MyDrive/KIA_AVATAR/Scripts/../knowledge\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[PROM]\\n\")\n",
        "    fw.write(\"knowledge_dir=/opt/knowledge\\n\")\n",
        "    fw.write(\"prev_knowledge_dir=/knowledge\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[CHATGPT]\\n\")\n",
        "    fw.write(\"api_key=?\\n\")\n",
        "    fw.write(\"tokens_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[GOOGLE]\\n\")\n",
        "    fw.write(\"search_api_key=?\\n\")\n",
        "    fw.write(\"search_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[YANDEX]\\n\")\n",
        "    fw.write(\"spellcheck_api_key=?\\n\")\n",
        "    fw.write(\"spellcheck_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[GITHUB]\\n\")\n",
        "    fw.write(\"summary_api_key=?\\n\")\n",
        "    fw.write(\"summary_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "\n",
        "msg = \"\""
      ],
      "metadata": {
        "id": "qPsQctbNqUZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken==0.4.0 pyaspeller"
      ],
      "metadata": {
        "id": "1qkJvfDJsCAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        import pyaspeller\n",
        "        import tiktoken\n",
        "        import re\n",
        "        import configparser\n",
        "        import pathlib\n",
        "        import os\n",
        "        import time\n",
        "        import random\n",
        "        config = configparser.ConfigParser()\n",
        "        config.read('config.txt')\n",
        "        knowledge_dir = config[\"COLAB\"][\"knowledge_dir\"]\n",
        "        if knowledge_dir is None: knowledge_dir = \"./knowledge\"\n",
        "        pathlib.Path(knowledge_dir).mkdir(parents=True, exist_ok=True)\n",
        "        prev_knowledge_dir = config[\"COLAB\"][\"prev_knowledge_dir\"]\n",
        "        if prev_knowledge_dir is None: prev_knowledge_dir = \"../knowledge\"\n",
        "        pathlib.Path(prev_knowledge_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        def num_tokens_from_messages(model, messages):\n",
        "            \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "            try:\n",
        "                encoding = tiktoken.encoding_for_model(model)\n",
        "            except KeyError:\n",
        "                encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "            if model in [\"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k\", \"gpt-4-0613\"]:  # note: future models may deviate from this\n",
        "                num_tokens = 0\n",
        "                for message in messages:\n",
        "                    num_tokens += 4  # every message follows {role/name}\\n{content}\\n\n",
        "                    for key, value in message.items():\n",
        "                        num_tokens += len(encoding.encode(value))\n",
        "                        if key == \"name\":  # if there's a name, the role is omitted\n",
        "                            num_tokens += -1  # role is always required and always 1 token\n",
        "                num_tokens += 2  # every reply is primed with assistant\n",
        "                return num_tokens\n",
        "            else:\n",
        "                raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
        "\n",
        "        from pyaspeller import YandexSpeller\n",
        "        speller = YandexSpeller()\n",
        "\n",
        "        dict_databases = {\"pdf_database.txt\": \"info\", \"video_database.txt\": \"howto\"}\n",
        "        for key in sorted(dict_databases.keys()):\n",
        "            total_cnt = 0\n",
        "            last_01_md_level_01 = None\n",
        "            last_01_md_level_02 = None\n",
        "            last_01_md_level_03 = None\n",
        "            with open(os.path.join(prev_knowledge_dir, key), \"r\") as f:\n",
        "                f01_lines = []\n",
        "                for line in f.readlines():\n",
        "                    line = speller.spelled(line)\n",
        "                    time.sleep(random.randrange(1))\n",
        "                    if len(line) > 253:\n",
        "                        chunks, chunk_size = len(line)//253, 253\n",
        "                        lines = [ line[i:i+chunk_size] for i in range(0, chunks, chunk_size)]\n",
        "                        line = \" ########## \".join(lines)\n",
        "                    if re.match((\"^#[^#]\"), line) is not None:\n",
        "                        last_01_md_level_01 = line\n",
        "                        last_01_md_level_02 = None\n",
        "                        last_01_md_level_03 = None\n",
        "                    if re.match((\"^##[^#]\"), line) is not None:\n",
        "                        last_01_md_level_02 = line\n",
        "                        last_01_md_level_03 = None\n",
        "                    if re.match((\"^###[^#]\"), line) is not None:\n",
        "                        last_01_md_level_03 = line\n",
        "\n",
        "                    cur_tokens = num_tokens_from_messages(\"gpt-3.5-turbo-16k\", [{\"\": '\\n'.join(f01_lines)}])\n",
        "                    f01_new_lines = [line]\n",
        "                    for s in f01_lines:\n",
        "                        f01_new_lines.append(s)\n",
        "                    next_tokens = num_tokens_from_messages(\"gpt-3.5-turbo-16k\", [{\"\": '\\n'.join(f01_new_lines)}])\n",
        "                    if next_tokens > 1024:\n",
        "                        print(f\"{key} - {total_cnt}\")\n",
        "                        print(f\"{last_01_md_level_01}\")\n",
        "                        print(f\"{last_01_md_level_02}\")\n",
        "                        print(f\"{last_01_md_level_03}\")\n",
        "                        print(\"BEGIN\")\n",
        "                        filepath_01 = os.path.join(knowledge_dir, f\"{dict_databases[key]}-{total_cnt}.md\")\n",
        "                        with open(filepath_01, \"w\") as f01:\n",
        "                            for f01_line in f01_lines:\n",
        "                                f01_line = re.sub(\"^####\", \"##### \", f01_line)\n",
        "                                f01_line = re.sub(\"^###\", \"#### \", f01_line)\n",
        "                                f01_line = re.sub(\"^##\", \"### \", f01_line)\n",
        "                                f01_line = re.sub(\"^#\", \"## \", f01_line)\n",
        "                                f01.write(f01_line)\n",
        "                        f01_lines = []\n",
        "                        if last_01_md_level_01 is not None:\n",
        "                            f01_lines.append(last_01_md_level_01.replace(\"^#\", f\"#{total_cnt}  \"))\n",
        "                        if last_01_md_level_02 is not None:\n",
        "                            f01_lines.append(last_01_md_level_02.replace(\"^##\", f\"##{total_cnt}  \"))\n",
        "                        if last_01_md_level_03 is not None:\n",
        "                            f01_lines.append(last_01_md_level_03.replace(\"^###\", f\"###{total_cnt}  \"))\n",
        "                        if re.match((\"^#\"), line) is None:\n",
        "                            f01_lines.append(line)\n",
        "                        total_cnt = total_cnt + 1\n",
        "                        print(\"END\")\n",
        "                    else:\n",
        "                        f01_lines.append(line)\n",
        "                filepath_01 = os.path.join(knowledge_dir, f\"{dict_databases[key]}-{total_cnt}.md\")\n",
        "                with open(filepath_01, \"w\") as f01:\n",
        "                    for f01_line in f01_lines:\n",
        "                        f01.write(f01_line.replace(\"^####\", \"##### \").replace(\"^###\", \"#### \").replace(\"^##\", \"### \").replace(\"^#\", \"## \"))\n",
        "                with open(os.path.join(knowledge_dir, f\"{dict_databases[key]}.md\"), \"w\") as fw01:\n",
        "                    fw01.write(f\"# {dict_databases[key]}\\n\")\n",
        "                    for cnt in range(0, total_cnt):\n",
        "                        filepath_01 = os.path.join(knowledge_dir, f\"{dict_databases[key]}-{cnt}.md\")\n",
        "                        with open(filepath_01, \"r\") as fr01:\n",
        "                            for line in fr01.readlines():\n",
        "                                fw01.write(line)\n",
        "                with open(os.path.join(knowledge_dir, f\"COPY.md\"), \"a\") as fw01:\n",
        "                    fw01.write(f\"# {dict_databases[key]}\\n\")\n",
        "                    for cnt in range(0, total_cnt):\n",
        "                        filepath_01 = os.path.join(knowledge_dir, f\"{dict_databases[key]}-{cnt}.md\")\n",
        "                        with open(filepath_01, \"r\") as fr01:\n",
        "                            for line in fr01.readlines():\n",
        "                                fw01.write(line)\n",
        "\n",
        "        print(msg, \" ... OK\")"
      ],
      "metadata": {
        "id": "ODHDRl6QqfD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}