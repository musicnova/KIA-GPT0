{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsFGkXMMwcX3"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nH2KyinoxhE",
        "outputId": "0e317be1-5479-4af8-9b1d-890c72b391d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: langchain==0.0.231 in /usr/local/lib/python3.10/dist-packages (0.0.231)\n",
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.10/dist-packages (1.10.8)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (3.8.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (0.5.14)\n",
            "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (0.0.20)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.2.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (0.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.231) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip  install  tiktoken==0.4.0  langchain==0.0.231 openai==0.27.8 faiss-cpu==1.7.4 gspread oauth2client nltk pydantic==1.10.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNTJkb02qexK"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "#database\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#from langchain.document_loaders import TextLoader\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "import ipywidgets as widgets\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh42jUHVy3fq"
      },
      "outputs": [],
      "source": [
        "MODEL_GPT_3_5_TURBO_16K = ['gpt-3.5-turbo-16k', 0.003, 0.004]\n",
        "MODEL_GPT_3_5_TURBO = ['gpt-3.5-turbo', 0.0015, 0.002]  # 4,097 tokens\n",
        "MODEL_GPT_3_5_TURBO_INSTRUCT = ['gpt-3.5-turbo-instruct', 0.0015, 0.002]  # 4,097 tokens\n",
        "MODEL_GPT_4 = ['gpt-4', 0.03, 0.06]  # 8,192 tokens\n",
        "SELECT_MODEL_GPT = MODEL_GPT_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSdHAWANqs7C",
        "outputId": "c562a9d0-66ce-40db-96a3-3593a897430f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAafR4VwqtFS"
      },
      "outputs": [],
      "source": [
        "def insert_newlines(textstr: str, max_len: int = 170) -> str:\n",
        "    words = textstr.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + \" \" + word) > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += \" \" + word\n",
        "    lines.append(current_line)\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YFsrIhi4Yct"
      },
      "outputs": [],
      "source": [
        "# функция для загрузки документа по ссылке из гугл драйв\n",
        "def load_document_text(url: str) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnSehGphiewU"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "import re\n",
        "\n",
        "def load_file_knowledge(file_path: str) -> str:\n",
        "    # Чтение текстового файла\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    headers_to_split_on = [\n",
        "        (\"#\", \"router\"),\n",
        "        (\"##\", \"Header2\"),\n",
        "        (\"###\", \"Header3\"),\n",
        "        (\"####\", \"Header4\"),\n",
        "    ]\n",
        "\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "    md_header_splits = markdown_splitter.split_text(text)\n",
        "\n",
        "    # Предполагается, что FAISS и OpenAIEmbeddings были импортированы или определены где-то выше\n",
        "    vectordateBase = FAISS.from_documents(md_header_splits, OpenAIEmbeddings())\n",
        "\n",
        "    return vectordateBase\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CrXhbfVqtP_"
      },
      "outputs": [],
      "source": [
        "knowledge_base = load_file_knowledge('database.md')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "technology_template = \"\"\"You are a very smart assistant for KIA. You know everything about the technologies used in KIA cars.\n",
        "You are excellent at answering questions briefly and clearly about the technologies used in KIA cars.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "parts_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "oils_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "accessories_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "warranty_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "service_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "sales_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "models_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "apps_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "promotion_template = \"\"\"You are a very smart assistant for KIA. Do you know everything about KIA car models\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "tech_template = \"\"\"You are a very smart assistant for KIA. You know everything about KIA technologies\\\n",
        "You are excellent at answering physics questions concisely and clearly. \\\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"models\",\n",
        "        \"description\": \"Good for answering questions about models kia auto\",\n",
        "        \"prompt_template\": models_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"tech\",\n",
        "        \"description\": \"Good for answering about questions technological kia\",\n",
        "        \"prompt_template\": tech_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"technology\",\n",
        "        \"description\": \"Good for answering questions about Kia technology.\",\n",
        "        \"prompt_template\": technology_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"parts\",\n",
        "        \"description\": \"!!!!!!!!!!!!!Good for answering about questions technological kia\",\n",
        "        \"prompt_template\": parts_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"oils\",\n",
        "        \"description\": \"!!!!!!!!!!!Good for answering questions about models kia auto\",\n",
        "        \"prompt_template\": oils_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"accessories\",\n",
        "        \"description\": \"!!!!!!!!!!!Good for answering about questions technological kia\",\n",
        "        \"prompt_template\": accessories_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"warranty\",\n",
        "        \"description\": \"!!!!!!!!!!!!!Good for answering questions about models kia auto\",\n",
        "        \"prompt_template\": warranty_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"service\",\n",
        "        \"description\": \"Good for answering about questions technological kia\",\n",
        "        \"prompt_template\": service_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"models\",\n",
        "        \"description\": \"Good for answering questions about models kia auto\",\n",
        "        \"prompt_template\": models_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"tech\",\n",
        "        \"description\": \"Good for answering about questions technological kia\",\n",
        "        \"prompt_template\": tech_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"tech\",\n",
        "        \"description\": \"Good for answering about questions technological kia\",\n",
        "        \"prompt_template\": tech_template,\n",
        "    },\n",
        "]\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "default_chain = ConversationChain(llm=llm, output_key=\"text\")\n",
        "\n",
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
        "\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)\n",
        "print(destinations_str)\n",
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "\n",
        "\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
        "\n",
        "\n",
        "\n",
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chains,\n",
        "    default_chain=default_chain,\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLhnEzASR7G8",
        "outputId": "a8084c32-9bff-4279-efe6-5622f22b825f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models: Good for answering questions about models kia auto\n",
            "tech: Good for answering about questions technological kia\n",
            "technology: Good for answering questions about Kia technology.\n",
            "parts: !!!!!!!!!!!!!Good for answering about questions technological kia\n",
            "oils: !!!!!!!!!!!Good for answering questions about models kia auto\n",
            "accessories: !!!!!!!!!!!Good for answering about questions technological kia\n",
            "warranty: !!!!!!!!!!!!!Good for answering questions about models kia auto\n",
            "service: Good for answering about questions technological kia\n",
            "models: Good for answering questions about models kia auto\n",
            "tech: Good for answering about questions technological kia\n",
            "tech: Good for answering about questions technological kia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsEKLyifvEto"
      },
      "outputs": [],
      "source": [
        "def answer_index(topic, temp=0.1, top_similar_documents=3):\n",
        "\n",
        "        router_result = router_chain.__call__({\"input\": topic})\n",
        "        chosen_route = router_result['destination']\n",
        "        next_inputs = router_result['next_inputs']\n",
        "\n",
        "        print(f\"Выбранный маршрут: {chosen_route}\")\n",
        "        print(f\"Следующие входные данные: {next_inputs}\")\n",
        "        docs = knowledge_base.similarity_search_with_score(topic, filter=dict(router = chosen_route), k=top_similar_documents)\n",
        "\n",
        "       # docs = knowledge_base.similarity_search_with_score(topic, k=top_similar_documents)\n",
        "\n",
        "        responses = []\n",
        "        for i, (doc, score) in enumerate(docs):\n",
        "            if score < 1: # ТУТ ТЫ МОЖЕШЬ УПРАВЛЯТЬ праметром Л2 для чанков. 0..1\n",
        "                content = doc.page_content\n",
        "                response = f'\\n=====================Отрывок документа №{i + 1}=====================\\n{content}\\n'\n",
        "                print(f'\\n=====================Отрывок документа №{i + 1}=====================\\n')\n",
        "                print(f'=== score = {score}  Metadata документа ------------ {doc.metadata}')\n",
        "                print(f'\\n{content}\\n')\n",
        "                responses.append(response)\n",
        "\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\",\n",
        "             \"content\": f\"Документ с информацией для ответа клиенту: {responses}\\n\\nВопрос клиента: \\n{topic}\"}\n",
        "        ]\n",
        "\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=SELECT_MODEL_GPT[0],\n",
        "            messages=messages,\n",
        "            temperature=temp\n",
        "        )\n",
        "\n",
        "        answer = completion.choices[0].message.content\n",
        "\n",
        "        return insert_newlines(answer)  # возвращает ответ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8N4WuC7qtKO"
      },
      "outputs": [],
      "source": [
        "def run_dialog():\n",
        "\n",
        "    while True:\n",
        "        user_question = input('\\nКлиент: ')\n",
        "        if ((user_question.lower() == 'stop') or (user_question.lower() == 'стоп')):\n",
        "            break\n",
        "        answer = answer_index(user_question)\n",
        "        print('\\nМенеджер: ', answer+'\\n\\n')\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCBakZx6qtVM"
      },
      "outputs": [],
      "source": [
        "# Промпт моделей машин\n",
        "prompt = load_document_text ('https://docs.google.com/document/d/1i8HA7cX4Ut-tb9rf8wOgERU7lLe66xJYscizGtSSJl0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWY1AS2GvTN5",
        "outputId": "f6105383-a0a8-490a-e55f-90e10ee28911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Клиент: Привет\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выбранный маршрут: None\n",
            "Следующие входные данные: {'input': 'Привет'}\n",
            "\n",
            "Менеджер:   Здравствуйте! Как я могу помочь вам с информацией о продуктах и услугах KIA сегодня?\n",
            "\n",
            "\n",
            "\n",
            "Клиент: стоп\n"
          ]
        }
      ],
      "source": [
        "run_dialog()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}