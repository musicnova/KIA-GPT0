{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7tWvV9r6BY6"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Draft V.3\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Загрузка модели и токенизатора\n",
        "model_name = \"cointegrated/rubert-tiny2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def get_sentence_vector(sentence):\n",
        "    # Токенизация предложения\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "    # Получение выходов модели\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Использование среднего значения последнего скрытого состояния для получения вектора предложения\n",
        "    sentence_vector = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "    return sentence_vector\n"
      ],
      "metadata": {
        "id": "DM6s9g9Y6Ez8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка датасета\n",
        "dataset_path = \"//content/drive/MyDrive/Стажировка КИА/Диалоги/database.md\"\n",
        "# https://drive.google.com/file/d/1LNgIg5In2nL-WGzm3kYRHUFB_i6pCPUL/view?usp=sharing\n",
        "\n",
        "# Чтение файла с расширением .md и разделение текста на диалоги по символу ##\n",
        "with open(dataset_path, 'r') as file:\n",
        "    data = file.read().split('##')\n",
        "    #data = file.read()\n",
        "\n",
        "# Создание DataFrame из списка диалогов\n",
        "df_manager = pd.DataFrame(data, columns=['dialog'])\n",
        "\n",
        "# Создание векторов для каждого диалога\n",
        "df_manager['vector'] = df_manager['dialog'].apply(get_sentence_vector)\n",
        "\n",
        "# Измерение косинусного сходства между векторами\n",
        "similarities = cosine_similarity(np.concatenate(df_manager['vector'].values))\n"
      ],
      "metadata": {
        "id": "rdMNoo3z6Evd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Отбор диалогов по близости смысла\n",
        "threshold = 0.8\n",
        "selected_dialogs = []\n",
        "\n",
        "selected = [(df_manager.iloc[i]['dialog'], df_manager.iloc[j]['dialog'])\n",
        "            for i, row in enumerate(similarities)\n",
        "            for j, value in enumerate(row) if i != j and value > threshold]\n",
        "selected_dialogs = selected\n",
        "\n",
        "# Запись результатов в файл\n",
        "with open('sep_dialog.txt', 'w') as file:\n",
        "    file.write(f\"Количество диалогов с близостью {threshold*100}%: {len(selected_dialogs)}\\n\")\n",
        "    for pair in selected_dialogs:\n",
        "        file.write(f\"{pair[0]} - {pair[1]}\\n\")\n"
      ],
      "metadata": {
        "id": "9WX--BWp6Erk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}