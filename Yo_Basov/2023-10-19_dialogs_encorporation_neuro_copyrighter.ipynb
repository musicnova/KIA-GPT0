{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Установка и загрузка необходимых модулей"
      ],
      "metadata": {
        "id": "zw3LTE6h2cI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu langchain openai tiktoken"
      ],
      "metadata": {
        "id": "yIYARB1eEZuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "import os\n",
        "import getpass\n",
        "import re\n",
        "import requests\n",
        "import openai\n",
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "2u7zPtrKEZxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "id": "tLT_7I9fEZ0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ac8435-1da6-4fbd-d9c9-d624f5281e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создаем текстовый файл с диалогами из Гугл таблицы"
      ],
      "metadata": {
        "id": "5IXdHPQPU3du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# функция для загрузки таблицы по ссылке из гугл драйв\n",
        "#def load_xls_pd(url: str) -> str:\n",
        "def load_xls_pd(url: str, sheet_name: str = 0) -> str:\n",
        "\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/spreadsheets/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Sheets URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    if sheet_name is None:\n",
        "        raise ValueError('Invalid sheet_name')\n",
        "\n",
        "    # Download the table as pandas\n",
        "    response = requests.get(f'https://docs.google.com/spreadsheets/d/{doc_id}/export?format=xlsx')\n",
        "    response.raise_for_status()     #проверяет статус код ответа. Если получен ответ с кодом ошибки (4xx или 5xx), вызывается исключение HTTPError.\n",
        "    #data = pd.read_excel(BytesIO(response.content), sheet_name=0)  #чтение первого листа из книги\n",
        "    data = pd.read_excel(BytesIO(response.content),sheet_name = sheet_name, header=None) #чтение конкретного листа из Книги Excel\n",
        "\n",
        "    ''' Разъяснение:\n",
        "        Когда мы хотим прочитать данные Excel с помощью функции pd.read_excel(), она требует передачи ей пути к файлу или объекта, представляющего файл.\n",
        "        В параметре io функции pd.read_excel() необходимо указать путь к файлу (в виде строки, содержащей путь к файлу) или объект файлового типа (такой как BufferedWriter, BufferedReader и другие).\n",
        "        response.content возвращает содержимое ответа на запрос HTTP в виде байтового массива (bytes array).\n",
        "        Чтобы передать эти данные в функцию pd.read_excel(), нужно создать объект файла из байтового массива.\n",
        "        Для этой цели используется объект BytesIO из модуля io, который предоставляет интерфейс для работы с данными в памяти, как если бы они находились в файле.\n",
        "    '''\n",
        "    return data\n",
        "\n",
        "# Шаг 1: Загрузить xlsx файл из Google Drive\n",
        "google_sheet_url = \"https://docs.google.com/spreadsheets/d/1uKrXGbXKhbvKjYU7Ao_XlsS0vQgOy8UaQxD-nZ3M8Sg/edit?usp=sharing\"\n",
        "sheet_name='dialogs_2023-09-11_20-54-18.csv'\n",
        "\n",
        "#data = load_xls_pd(google_sheet_url)   #если в таблице только один лист\n",
        "data = load_xls_pd(google_sheet_url, sheet_name)\n",
        "\n",
        "# Шаг 2: Извлечь столбец с диалогами\n",
        "text_column = data[data.columns[1]]\n",
        "\n",
        "# Шаг 3: Заменить \"operatorMessage: Здравствуйте\" на \"<operatorMessage: Здравствуйте>\" для удобства деления на чанки в дальнейшем\n",
        "text_column = text_column.str.replace(\"operatorMessage: Здравствуйте\", \"<operatorMessage: Здравствуйте>\")\n",
        "\n",
        "# Шаг 4: Сохранить в файл \"Dialogs__.txt\" в своей папке\n",
        "file_path = \"/content/kia_dialogs.txt\"\n",
        "\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in text_column:\n",
        "        f.write(str(text) + \"\\n\")\n",
        "\n",
        "print(\"Файл kia_dialog.txt успешно сохранен!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUEv2UCCVDeL",
        "outputId": "352284e0-72d4-454a-af0d-4ed76eec31f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл kia_dialog.txt успешно сохранен!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функция для загрузки диалогов из Гугл докс"
      ],
      "metadata": {
        "id": "aaPKfe1wgWvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_document_text(url: str) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "ihDA08J6EZ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Деление на чанки текстового файла"
      ],
      "metadata": {
        "id": "BSm4zBGxhHD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"/content/kia_dialogs.txt\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "SnNxyFEpaDfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#type(documents)"
      ],
      "metadata": {
        "id": "WQM9nMvGbijG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(separator=\"<\", chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "'''source_chunks = []     #разные методы деления текста\n",
        "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "for chunk in splitter.split_text(documents):\n",
        "    source_chunks.append(Document(page_content=chunk, metadata={}))'''"
      ],
      "metadata": {
        "id": "ZXft8Qvscnfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# всего получилось чанков:\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOJxop4vdEDo",
        "outputId": "c313df44-7785-4d5c-82f2-9f7c580b961a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2334"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# первый чанк\n",
        "page_content = docs[0].page_content\n",
        "# длина первого чанка\n",
        "print(len(page_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cr0zGo6dIWM",
        "outputId": "9cec7e75-b4bb-4986-8162-2ac092c29406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# третий чанк:\n",
        "page_content = docs[4]\n",
        "page_content\n",
        "#print(page_content)\n",
        "# длина третьего чанка\n",
        "#print(len(page_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYLiGo_xeSwg",
        "outputId": "1928b191-363a-411c-fe17-a9e7798ef090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='operatorMessage: Здравствуйте>.\\nУточните, пожалуйста, какая информация Вас интересует? clientMessage: Подскажите пожалуйста,  какое масло сейчас рекомендуете для киа рио 1,6 operatorMessage: Уточните, пожалуйста, как к Вам можно обращаться? clientMessage: У официальных дилеров в нашем городе разнятся данные clientMessage: Ну я же уже написала Екатерина  clientMessage: Подскажите пожалуйста что с маслом? Что рекомендуете? Какие допуски? Вязкость?  clientMessage: Вы ответите?  operatorMessage: Екатерина, очень приятно. К сожалению, переписка не отображается в полном объеме. operatorMessage: Рекомендации по эксплуатации автомобиля подробно описаны в Руководстве по эксплуатации. operatorMessage: Информацию о допустимых или рекомендуемых производителем и дистрибьютором марках и параметрах технических жидкостей, согласно регламенту, предоставляют официальные дилеры, которые для обслуживания автомобилей сертифицированы. clientMessage: Там по маслу нечего нет кроме вязкости clientMessage: Ну хорошо почему у официальный дилеров информация разная? clientMessage: Одни говорят, что вот только это масло-Тотал,  другие называют ещё несколько? operatorMessage: Если специалисты дилерского центра по Вашему вопросу информацию не предоставили, рекомендуем обращаться к руководству дилерского центра за содействием в решении вопроса. \\nМожет представлен список из рекомендуемых марок и допустимых параметров. \\nСписок дилеров доступен на официальном сайте по ссылке: https://www.kia.ru/dealers/. operatorMessage: Уточните, пожалуйста, могу еще чем-либо Вам помочь? clientMessage: Вы и тут не чем не помогли.  Нет у Вас сервиса как у марки к сожалению.', metadata={'source': '/content/kia_dialogs.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обращение к ChatGPT для обработки диалогов"
      ],
      "metadata": {
        "id": "awRB1RGB1ALT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка температуры и вывода ChatGPT"
      ],
      "metadata": {
        "id": "J5ZnJI1Lg4C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature=0          # подставьте сюда необходимое значение\n",
        "verbose=0              # подставьте сюда необходимое значение"
      ],
      "metadata": {
        "id": "vL7IXWuxOhua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#функция удобочитаемого вывода\n",
        "def insert_newlines(text: str, max_len: int = 170) -> str:\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + word + \" \") > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += word + \" \"\n",
        "    lines.append(current_line)\n",
        "    return \" \".join(lines)"
      ],
      "metadata": {
        "id": "R2QYgqbkBjRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инструкция для GPT, которая будет подаваться в system\n",
        "system_prompt = load_document_text('https://docs.google.com/document/d/1UrEzeIboxdz9rlaMcgZGi7DqNoMPvxHlgnNRQyWcBEw/edit?usp=sharing')   # подставьте сюда необходимое значение\n",
        "user_prompt = load_document_text('https://docs.google.com/document/d/1VS5kGrUMKM-vc3d7oTdsrlQiLHRAmTZ8rM5Mb-MwO-8/edit?usp=sharing')   # подставьте сюда необходимое значение"
      ],
      "metadata": {
        "id": "YNBOMnfnOhw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подключение Google Disk для сохранения обработанной базы"
      ],
      "metadata": {
        "id": "-oDx-MZUUzKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPYq9ihFp03A",
        "outputId": "7b930be5-6f98-4e00-99b2-641e1b49627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "Zjdx2vTmdmuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itog = \"\"\n",
        "#for i in range(len(docs)):\n",
        "for i in range(2133, 2334):\n",
        "    #print(docs[i].page_content)  # Вывод текущего элемента списка\n",
        "    print(i)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"{user_prompt}\\n{docs[i].page_content}\"}\n",
        "    ]\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=messages,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    answer = f'\\n{insert_newlines(completion.choices[0].message.content)}'\n",
        "    #itog += f'\\n{answer}'\n",
        "\n",
        "    # запись в файл\n",
        "    with open(\"/content/drive/MyDrive/Stazhirovka_Kia/Dialogs/Useful_from_Dialog.txt\", \"a\") as file:\n",
        "        file.write(answer)\n",
        "    clear_output()"
      ],
      "metadata": {
        "id": "YK8gXz7H0gdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZyySJLG6096",
        "outputId": "0a016430-ffaf-4726-e2c1-c5d61f0cc78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/kia_dialogs.txt /content/drive/MyDrive/Stazhirovka_Kia/Dialogs/"
      ],
      "metadata": {
        "id": "eOvchwa27vxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "id": "1GqlCjZ-_i16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ОБЪЕДИНЯЕМ схожие ТЕМЫ"
      ],
      "metadata": {
        "id": "hrHwMWYQtaX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ЗАПРОС в ChatGPT"
      ],
      "metadata": {
        "id": "9BCh6TiOwdwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ChatCompletion(model,  # указываем модель\n",
        "                       messages,     # словарь запроса\n",
        "                       temp=0.2):    # температуру\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature = temp\n",
        "      )\n",
        "\n",
        "    # print(f'{completion[\"usage\"][\"total_tokens\"]} токенов использовано всего (вопрос-ответ).')\n",
        "    # print('ЦЕНА запроса с ответом :', 0.0015*(completion[\"usage\"][\"total_tokens\"]/1000), ' $')\n",
        "    # print('===========================================: \\n')\n",
        "    return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "pkVyYZ4kwXDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_merge_topics(model_topics = \"gpt-3.5-turbo-16k\"):\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
        "      {\"role\": \"user\", \"content\": f\"\"\"Проанализируй Темы и подтемы Семинара: {content_topics}.  #как модель может подгрузить большой файл, где он разбивается???\n",
        "\n",
        "Необходимо объединить похожие по смыслу темы или подтемы, записать компактно.\n",
        "При необходимости перефразировать тему или подтему. Дай корректный список.\n",
        "Темы оформи _#, а подтемы оформи ##_.\n",
        "Используй только такой пример, ничего не добавляй лишнего.\n",
        "Пример составления списка:\n",
        "_#...\n",
        "##_...\n",
        "_#...\n",
        "##_...\n",
        "\"\"\"}\n",
        "]\n",
        "  # example token count from the function defined above\n",
        "  # print(f\"{self.num_tokens_from_messages(messages=messages)} токенов использовано на вопрос \\n\")\n",
        "  try:\n",
        "    #content_topics = get_ChatCompletion(model_topics, messages)\n",
        "    itog_content_topics = get_ChatCompletion(model_topics, messages)\n",
        "    print('Итоговый список тем и подтем: ')\n",
        "    print(itog_content_topics)\n",
        "    with open(f'{file_path}_{file_name[:20]}__Topic_Subtopic_Final.txt', \"w\") as f:\n",
        "      f.write(itog_content_topics)\n",
        "  except:\n",
        "    print(\"Модель в настоящее время перегружена. Попробуйте позже.\")\n"
      ],
      "metadata": {
        "id": "4SM0IqIrrSJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/'\n",
        "file_name = 'Dialogs'\n",
        "#system_promt =       #уже есть выше"
      ],
      "metadata": {
        "id": "qr-17gpDxeXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_topics = load_document_text('https://docs.google.com/document/d/1X8a37OKyx5YUGAPYjNSYq-QP-pxPYpCp2XTYGmp4AzE/edit?usp=sharing')"
      ],
      "metadata": {
        "id": "x9jiEX18rR8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_merge_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxi4U1Jm31UZ",
        "outputId": "ed90b241-eddb-4a70-b570-7c400ec1498f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель в настоящее время перегружена. Попробуйте позже.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Взаимодействие с векторной базой"
      ],
      "metadata": {
        "id": "j_9Rcxiy0ZSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Перевод в эмбеддинги и FAISS"
      ],
      "metadata": {
        "id": "UjP4ddAhgH3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализирум модель эмбеддингов\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Создадим индексную базу из разделенных фрагментов текста\n",
        "db = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "J_ASkEFVE8Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохранение и загрузка векторной базы из диалогов локально."
      ],
      "metadata": {
        "id": "JzEFACsUoIUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db.save_local(\"faiss_index\")    #Сохранение локальной векторной базы\n",
        "new_db = FAISS.load_local(\"faiss_index\", embeddings)   #Загрузка локальной векторной базы"
      ],
      "metadata": {
        "id": "zsj3hmoToFhb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}