{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ЧЕРНОВОЙ ВАРИАНТ парсит pdf веб сайта\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP5yvKmI-5Ls",
        "outputId": "0347234a-c529-4a61-ea58-fcebd24c215c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"config.txt\", \"w\") as fw:\n",
        "    fw.write(\"[COLAB]\\n\")\n",
        "    fw.write(\"knowledge_dir=/content/drive/MyDrive/KIA_AVATAR/Scripts/knowledge\\n\")\n",
        "    fw.write(\"prev_knowledge_dir=/content/drive/MyDrive/KIA_AVATAR/Scripts/../knowledge\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[PROM]\\n\")\n",
        "    fw.write(\"knowledge_dir=/opt/knowledge\\n\")\n",
        "    fw.write(\"prev_knowledge_dir=/knowledge\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[CHATGPT]\\n\")\n",
        "    fw.write(\"api_key=?\\n\")\n",
        "    fw.write(\"tokens_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[GOOGLE]\\n\")\n",
        "    fw.write(\"search_api_key=?\\n\")\n",
        "    fw.write(\"search_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[YANDEX]\\n\")\n",
        "    fw.write(\"spellcheck_api_key=?\\n\")\n",
        "    fw.write(\"spellcheck_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "    fw.write(\"[GITHUB]\\n\")\n",
        "    fw.write(\"summary_api_key=?\\n\")\n",
        "    fw.write(\"summary_limit=0\\n\")\n",
        "    fw.write(\"\\n\")\n",
        "\n",
        "msg = \"\""
      ],
      "metadata": {
        "id": "qjK-12Rx-5JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        import configparser\n",
        "        import pathlib\n",
        "        import shutil\n",
        "        import os\n",
        "        config = configparser.ConfigParser()\n",
        "        config.read('config.txt')\n",
        "        knowledge_dir = config[\"COLAB\"][\"knowledge_dir\"]\n",
        "        if knowledge_dir is None: knowledge_dir = \"./knowledge\"\n",
        "        pathlib.Path(knowledge_dir).mkdir(parents=True, exist_ok=True)\n",
        "        prev_knowledge_dir = config[\"COLAB\"][\"prev_knowledge_dir\"]\n",
        "        if prev_knowledge_dir is None: prev_knowledge_dir = \"../knowledge\"\n",
        "        pathlib.Path(prev_knowledge_dir).mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copyfile(os.path.join(prev_knowledge_dir, \"video_database.txt\"),\n",
        "                        os.path.join(knowledge_dir, \"video_database.txt\"))\n",
        "        \"\"\"\n",
        "        import requests, json\n",
        "\n",
        "        headers = {'referer': 'https://www.kia.ru/'}\n",
        "        response = requests.get('https://www.kia.ru/ajax/video_bank/?limit=-1', headers=headers)\n",
        "\n",
        "        jsonObj = json.loads(response.text)\n",
        "\n",
        "        lists = jsonObj['content']['video_bank']['list']\n",
        "        groups = jsonObj['content']['video_bank']['groups']\n",
        "\n",
        "        urls = {}\n",
        "        for list in lists:\n",
        "            for video in lists[list]:\n",
        "                urls[video['video_link']] = video['name']\n",
        "\n",
        "        links = [i for i in urls.keys()]\n",
        "\n",
        "        print(links)\n",
        "\n",
        "\n",
        "\n",
        "        # Whisper.\n",
        "\n",
        "        # model_size = \"large-v2\"\n",
        "        # language = \"russian\"\n",
        "\n",
        "        # Включите поддержку GPU\n",
        "        # Зависимости, импорты и настройка\n",
        "\n",
        "        # !pip install -qq git+https://github.com/openai/whisper.git\n",
        "        # !pip install -qq langchain\n",
        "        # !pip install -qq openai\n",
        "        # !pip install -qq google-search-results\n",
        "\n",
        "        # !pip install -qq python-docx\n",
        "        # !pip install -U pytube\n",
        "        # !pip install -qq tiktoken\n",
        "        import whisper\n",
        "        try:\n",
        "          modelWhisper = whisper.load_model(\"large-v2\")\n",
        "          print(\"Загружена модель Whisper large-v2\")\n",
        "        except:\n",
        "          print(\"ОШИБКА загрузки Whisper.\")\n",
        "\n",
        "\n",
        "\n",
        "        import os\n",
        "\n",
        "\n",
        "\n",
        "        from psutil import virtual_memory\n",
        "        ram_gb = virtual_memory().total / 1e9\n",
        "        print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "        if ram_gb < 20:\n",
        "          print('Not using a high-RAM runtime')\n",
        "        else:\n",
        "          print('You are using a high-RAM runtime!')\n",
        "\n",
        "          #@title Импорт библиотек\n",
        "        import os\n",
        "        import re\n",
        "        from pathlib import Path\n",
        "        import json\n",
        "        import ipywidgets as widgets\n",
        "        from IPython.display import display\n",
        "        from pytube import YouTube\n",
        "        from tqdm.auto import tqdm\n",
        "        import getpass\n",
        "        import pickle\n",
        "\n",
        "        import torch\n",
        "        import tiktoken\n",
        "        import whisper\n",
        "        import openai\n",
        "\n",
        "        from docx import Document\n",
        "        from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "\n",
        "        # Сохраняем во временное хранилище\n",
        "        import codecs\n",
        "\n",
        "        ### @title  Импорты  OpenAI LLM\n",
        "        from langchain.chains import ConversationChain         # Импортируем класс для создания цепочек диалогов\n",
        "        from langchain.chat_models import ChatOpenAI           # Импортируем класс для работы с чатами на базе OpenAI\n",
        "        from langchain.llms import OpenAI\n",
        "        from langchain.memory import ConversationBufferMemory  # Импортируем класс для управления памятью диалогов\n",
        "        from langchain.prompts import (\n",
        "            ChatPromptTemplate,\n",
        "            MessagesPlaceholder,\n",
        "            SystemMessagePromptTemplate,\n",
        "            HumanMessagePromptTemplate,\n",
        "            PromptTemplate\n",
        "        )\n",
        "        from langchain.schema import (\n",
        "            AIMessage,\n",
        "            HumanMessage,\n",
        "            SystemMessage\n",
        "        )\n",
        "\n",
        "        class WorkerWhisperОpenAI():\n",
        "          def __init__(self, video_path = None, \\\n",
        "               Name = \"Видео1\", \\\n",
        "               NameLessons = \"Имя Урока\", \\\n",
        "               modelWhisper  = None, \\\n",
        "               whisper_file = None, \\\n",
        "               result_json_file = None, \\\n",
        "               chunks_pickle_file = None, \\\n",
        "               SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/ChatGPT/Video/TXT/', \\\n",
        "               modelОpenAI = 'gpt-3.5-turbo-0613'):   # 0301\n",
        "\n",
        "            self.modelОpenAI = modelОpenAI\n",
        "            self.YouTube_video_title = Name\n",
        "            self.NameLessons = NameLessons\n",
        "            self.SAVE_DIR = SAVE_DIR\n",
        "            self.modelWhisper = modelWhisper\n",
        "\n",
        "            # self.get_key_ОpenAI()\n",
        "            self.encoding = tiktoken.encoding_for_model(self.modelОpenAI)\n",
        "            self.titles_model = ChatOpenAI(temperature=0.1, max_tokens=300)\n",
        "            self.summarization_model = ChatOpenAI(temperature=0.1, max_tokens=1000)\n",
        "\n",
        "            self.video_path = video_path\n",
        "\n",
        "            # загружаем сохраненный\n",
        "            if whisper_file:\n",
        "                with open(whisper_file, 'rb') as pick:\n",
        "                  self.whisper_result = pickle.load(pick)\n",
        "\n",
        "            # загружаем сохраненный .json\n",
        "            if result_json_file:\n",
        "                with open(result_json_file, \"r\") as f:\n",
        "                    self.whisper_result = json.load(f)\n",
        "\n",
        "            # загружаем сохраненный .pickle\n",
        "            if chunks_pickle_file:\n",
        "                with open(chunks_pickle_file, 'rb') as pick:\n",
        "                  self.chunks = pickle.load(pick)\n",
        "\n",
        "\n",
        "          # Транскрибация\n",
        "          def get_whisper_result(self, ):\n",
        "\n",
        "              # RTX3090: 21 минут обработка видео длинной 2 часа 45 минут на модели large-v2\n",
        "              # Google Colab Tesla T4: 4 минут 52 секунды на обработку видео длинной 23 минуты 11 секунд на модели large-v2\n",
        "              self.whisper_result = self.modelWhisper.transcribe(str(self.video_path), fp16=True, language=\"russian\")\n",
        "\n",
        "              with open(f'{self.SAVE_DIR}{self.YouTube_video_title}_whisper.json', \"w\") as f:\n",
        "                f.write(str(self.whisper_result))\n",
        "\n",
        "              # with open(f'{self.SAVE_DIR}{self.YouTube_video_title}_whisper.pickle', 'wb') as pick:\n",
        "              #     pickle.dump(self.whisper_result, pick, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "              print('Файл whisper сохранен.')\n",
        "\n",
        "        ### ---------------------------------------------------\n",
        "        #### Группируем сегменты по токенам, чтобы в сегменте было не более 3000 токенов\n",
        "          def grouping_segments_by_tokens(self):\n",
        "\n",
        "              ## @title Группируем сегменты по предложениям\n",
        "              def merge_chunks_by_sentences(chunks):\n",
        "                  merged_chunks = []\n",
        "                  current_chunk = None\n",
        "                  for chunk in chunks:\n",
        "                      if not current_chunk:\n",
        "                          current_chunk = {\"text\": chunk[\"text\"]}\n",
        "                      elif current_chunk[\"text\"][-1] in ['.', '!', '?']:\n",
        "                          merged_chunks.append(current_chunk)\n",
        "                          current_chunk = {\"text\": chunk[\"text\"]}\n",
        "                      else:\n",
        "                          current_chunk[\"text\"] += \" \" + chunk[\"text\"]\n",
        "                  if current_chunk:\n",
        "                      merged_chunks.append(current_chunk)\n",
        "                  return merged_chunks\n",
        "\n",
        "              sentences = merge_chunks_by_sentences(self.whisper_result[\"segments\"])\n",
        "              for sentence in sentences:\n",
        "                  if sentence[\"text\"][-1] != \".\":\n",
        "                    sentence[\"text\"] += \".\"\n",
        "\n",
        "              # with open(f'{self.SAVE_DIR}{self.YouTube_video_title}_collecting.pickle', 'wb') as pick:\n",
        "              #     pickle.dump(sentences, pick, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "              print(f\"Ранее было предложений: {len(self.whisper_result['segments'])}\")\n",
        "              print(f\"Стало предложений: {len(sentences)}\")\n",
        "              print(\"Группируем сегменты по токенам.\")\n",
        "\n",
        "              #@title Группируем сегменты по токенам(не более 3000)\n",
        "              def merge_chunks_by_tokens(chunks, max_tokens=3000):\n",
        "                  merged_chunks = []\n",
        "                  current_chunk = None\n",
        "                  for chunk_i, chunk in enumerate(chunks):\n",
        "                      chunk_tokens_count = len(self.encoding.encode(chunk[\"text\"]))\n",
        "                      if not current_chunk:\n",
        "                          current_chunk = {\"text\": chunk[\"text\"], \"tokens_count\": chunk_tokens_count}\n",
        "                      elif chunk_tokens_count + current_chunk[\"tokens_count\"] > max_tokens:\n",
        "                          merged_chunks.append(current_chunk)\n",
        "                          assert current_chunk[\"tokens_count\"] <= max_tokens + 1, current_chunk[\"tokens_count\"]\n",
        "                          current_chunk = {\"text\": chunk[\"text\"], \"tokens_count\": chunk_tokens_count}\n",
        "                      else:\n",
        "                          current_chunk[\"text\"] += \" \" + chunk[\"text\"]\n",
        "                          current_chunk[\"tokens_count\"] = len(self.encoding.encode(current_chunk[\"text\"]))\n",
        "\n",
        "                  if current_chunk:\n",
        "                      merged_chunks.append(current_chunk)\n",
        "                  return merged_chunks\n",
        "\n",
        "              try:\n",
        "                self.chunks = merge_chunks_by_tokens(sentences)\n",
        "                print(f\"Было предложений: {len(sentences)}\")\n",
        "                print(f\"Сгруппировали на  {len(self.chunks)}  блоков\")\n",
        "              except:\n",
        "                self.chunks = merge_chunks_by_tokens(self.whisper_result[\"segments\"])\n",
        "                print(f\"Альтернативный вариант. =========\")\n",
        "                print(f\"Сгруппировали на  {len(self.chunks)}  блоков\")\n",
        "\n",
        "              # with open(f'{self.SAVE_DIR}{self.YouTube_video_title}_chunks.pickle', 'wb') as pick:\n",
        "              #     pickle.dump(self.chunks, pick, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "              # print('Сгруппированные chunks - файл .pickle сохранен.')\n",
        "\n",
        "              # # Создаем новый документ\n",
        "              new_txt = ''\n",
        "              for chunk_i, chunk in enumerate(self.chunks):\n",
        "                  new_txt +=f\"<Chunk>\\n Урок:{self.NameLessons}\\n\"\n",
        "                  new_txt +=chunk[\"text\"] + \"\\n\\n\"\n",
        "\n",
        "              with open(f'{self.SAVE_DIR}{self.YouTube_video_title}_grouping.txt', \"w\") as f:\n",
        "                f.write(str(new_txt))\n",
        "              print(\"Создали новый документ\")\n",
        "\n",
        "\n",
        "              # Транскрибация\n",
        "\n",
        "\n",
        "              # https://youtu.be/twTVQ2F7Xnw\n",
        "              YouTube_video_title = \"Систематизация. 1 занятие\"\n",
        "              NameLessons = \"Систематизация бизнеса. Занятие №1.\"\n",
        "              SAVE_DIR = '/content/drive/MyDrive/_Projects_GPT/УИИ/'\n",
        "              project_name = 'TXT_УИИ/'\n",
        "\n",
        "              project_path = SAVE_DIR + project_name\n",
        "              video_path = f'{SAVE_DIR}Video/{YouTube_video_title}.mp4'\n",
        "              whisper_path = f'{SAVE_DIR}{project_name}{YouTube_video_title}_whisper.pickle'\n",
        "\n",
        "              # Готовим класс для работы\n",
        "              nature = WorkerWhisperОpenAI(video_path = video_path, \\\n",
        "                             Name = YouTube_video_title, \\\n",
        "                             NameLessons = NameLessons, \\\n",
        "                             modelWhisper = modelWhisper,\\\n",
        "                             SAVE_DIR = project_path)\n",
        "\n",
        "              # nature = WorkerWhisperОpenAI(Name = YouTube_video_title, \\\n",
        "              #                              whisper_file = whisper_path)\n",
        "\n",
        "              # nature = WorkerWhisperОpenAI(Name = YouTube_video_title, \\\n",
        "              #                              chunks_pickle_file = CHUNKS_pickle_file)\n",
        "              ### ---------------------------------------------------\n",
        "              # Собираем итоговую суммаризацию.\n",
        "                def summarization(self):\n",
        "                    print('Генерируем заголовки')\n",
        "                    # Генерируем заголовки\n",
        "                    for chunk in tqdm(self.chunks):\n",
        "                        messages = [\n",
        "                            SystemMessage(content='''\n",
        "              Ты профессиональный копирайтер.\n",
        "              Сделай короткий заголовок для фрагмента текста Лекции.\n",
        "              Необходимо уложиться в 300 токенов.\n",
        "              '''),\n",
        "                            HumanMessage(content=chunk[\"text\"])\n",
        "                        ]\n",
        "                        res = self.titles_model(messages)\n",
        "                        chunk[\"title\"] = res.content\n",
        "\n",
        "                    print('Генерируем пересказ')\n",
        "                    # Генерируем пересказ\n",
        "                    for chunk in tqdm(self.chunks):\n",
        "                        messages = [\n",
        "                            SystemMessage(content='''\n",
        "              Ты профессиональный копирайтер. У тебя большой опыт работы с Бизнесом в разных сферах, ты качественно структурируешь текст на Русском языке.\n",
        "\n",
        "              Сделай формальный технический пересказ того, о чем рассказывает лектор на семинаре. Пиши от имени Лектора.\n",
        "              Необходимо уложиться в 1000 токенов.\n",
        "              '''),\n",
        "              HumanMessage(content=chunk[\"text\"])\n",
        "                        ]\n",
        "                        res = self.summarization_model(messages)\n",
        "                        chunk[\"summarization\"] = res.content\n",
        "\n",
        "              # # Создаем новый документ\n",
        "              new_txt = ''\n",
        "              for chunk_i, chunk in enumerate(self.chunks):\n",
        "                  new_txt +=f\"<Chunk>\\n Урок:{self.NameLessons}\\n\"\n",
        "                  new_txt +=f\"Тема: {chunk['title']}\\n\"\n",
        "                  new_txt +=chunk[\"summarization\"] + \"\\n\\n\"\n",
        "\n",
        "              with open(f'{self.SAVE_DIR}{self.YouTube_video_title}_summ.txt', \"w\") as f:\n",
        "                f.write(str(new_txt))\n",
        "              print(\"Создали новый документ\")\n",
        "\n",
        "              # Транскрибация\n",
        "              nature.get_whisper_result()\n",
        "\n",
        "              # Группируем сегменты по токенам\n",
        "              nature.grouping_segments_by_tokens()\n",
        "\n",
        "              # Собираем итоговую суммаризацию.\n",
        "              # Генерация субтитров и анализ текста\n",
        "              nature.summarization()\n",
        "        \"\"\"\n",
        "\n",
        "        print(msg, \" ... OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbsX4WmMC-FA",
        "outputId": "5aa7d457-3c44-48ab-d3b4-8592bd78f0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ... OK\n"
          ]
        }
      ]
    }
  ]
}