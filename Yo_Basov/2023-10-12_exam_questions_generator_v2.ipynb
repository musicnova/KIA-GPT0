{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ЧЕРНОВОЙ ВАРИАНТ ПО НЕЙРО-ЭКЗАМЕНАТОРУ ДИАЛОГОВ С ПОМОЩЬЮ  В COLAB\n",
        "# https://www.youtube.com/watch?v=Tk2W92d30jY\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S62SU3VqBsrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbfa969-70d6-4e48-fbc8-3ad2472eba58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/drive/MyDrive/KIA_TEST/Examinator/KIA/BASE/\"\n",
        "!mkdir -p \"/content/drive/MyDrive/KIA_TEST/Examinator/KIA/BASE/\""
      ],
      "metadata": {
        "id": "Dy_ibKOXIOve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ПАМЯТКА\n",
        "**(1) Генерация тестовых вопросов с помощью Chat GPT 3.5:**\n",
        "1. Подготовлена тестовая БЗ v.1 - на 1 этапе взята вся инфа из файла \"Модель Пиканто\". БЗ пердставляет из себя 3 чанка с разделителем <...>, размеры чанков мене  1000 токенов, общий размер БЗ v.1 составляет 2400 токенов.\n",
        "2. Взят Промпт для генерации тестовых вопросов \"Генератор вопросов v.1 (617 t)\", общий размер Промпта \"Генератор\" v.1 составляет 617 токенов.\n",
        "3. Подаем на вход все 3 чанка с указанным промптом.\n",
        "4. На выходе получаем 10 тестовых вопросв, сгенерированных моделью 3.5 на основании тестовой БЗ\n",
        "\n",
        "(за основу взят Colab из 3 урока курса по Дообучению)\n",
        "\n",
        "Вопросы, Ответы и их Оценка - файл \"Тесты 1, 2\" (https://docs.google.com/spreadsheets/d/1br0LRb4ADpA2XkxtcSHFUXXV3pVdmDEG), лист - \"Диалоги (11.10 - Басов Ю.)\""
      ],
      "metadata": {
        "id": "T2BnEbtpS86D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(из Занятия №3)\n",
        "\n",
        "Структура базы знаний компании, предназначенной для предоставления ответов на вопросы клиентов в текстовом формате, является ключевым аспектом ее эффективного функционирования. Помните, что для ответов на вопросы будут использоваться чанки, наиболее релевантные запросу пользователя. Токим образом, структура базы знаний должна быть организованной, логической и удобной для поиска информации, чтобы обеспечить максимальную полезность и полноту информации в представленных для анализа чанках.\n",
        "\n",
        "Вот несколько ключевых принципов, которые следует учесть при формировании структуры базы знаний:\n",
        "\n",
        "* **Категоризация и классификация:** База знаний должна быть разделена на ясные и логически организованные блоки, соответствующие различным областям знаний или типам вопросов клиентов. Например, это могут быть разделы, связанные с продуктами, услугами, поддержкой, вопросами оплаты и т.д. В каждом блоке могут быть подблоки для дополнительной детализации. Это позволит LangChain легко найти релевантные чанки, соответствующие запросу.\n",
        "\n",
        "* **Иерархия:** База знаний может быть организована в виде иерархической структуры, где более общие темы располагаются на верхнем уровне, а более специфические вопросы и ответы находятся на более низких уровнях. Так проще контролировать наполненность базы знаний нужной информацией и обновлять ее при необходимости.\n",
        "\n"
      ],
      "metadata": {
        "id": "LSdsnVQNmCrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) Генерация по БЗ - KB_Picanto_test-questions_Eng_v.1"
      ],
      "metadata": {
        "id": "b8QXza8x-AFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка пакетов\n",
        "\n",
        "Разметка: интеллектуальные чанки\n"
      ],
      "metadata": {
        "id": "kOdn5HUmBMF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Помимо дробления на чанки \"вслепую\" при помощи различных сплиттеров, описанных в 1 занятии данного курса, можно дробить тексты на логические, смысловые чанки. Это гораздо более кропотливая и ресурсозатратная работа, но результаты оправдывают ожидания. Её суть заключается в том, что текст изначально разбивается вручную на логические блоки, отделенные определенным разделителем. Затем каждый логический отрезок делится на блоки указанного размера при помощи сплиттера.\n",
        "Вот, как это можно реализовать:"
      ],
      "metadata": {
        "id": "gh9vJ40RnBh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install  tiktoken==0.4.0  langchain==0.0.231 openai==0.27.8 chromadb gspread oauth2client nltk pydantic==1.10.8 faiss-cpu==1.7.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYOSrWNHBH-T",
        "outputId": "58623d66-e35a-42be-ea16-6bab8da914ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken==0.4.0\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.0.231\n",
            "  Downloading langchain-0.0.231-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting pydantic==1.10.8\n",
            "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu==1.7.4\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.231)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain==0.0.231)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.231)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.231) (3.0.0)\n",
            "Collecting huggingface_hub<0.18,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=e87a26fa505642016becfa532307760058bb7e445ea44777a2f504deceb0e871\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, faiss-cpu, websockets, uvloop, python-dotenv, pydantic, pulsar-client, overrides, mypy-extensions, marshmallow, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, openapi-schema-pydantic, langchainplus-sdk, huggingface_hub, coloredlogs, tokenizers, openai, onnxruntime, fastapi, dataclasses-json, langchain, chromadb\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.14 coloredlogs-15.0.1 dataclasses-json-0.5.14 faiss-cpu-1.7.4 fastapi-0.103.2 h11-0.14.0 httptools-0.6.0 huggingface_hub-0.17.3 humanfriendly-10.0 langchain-0.0.231 langchainplus-sdk-0.0.20 marshmallow-3.20.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.16.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pydantic-1.10.8 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tiktoken-0.4.0 tokenizers-0.14.1 typing-inspect-0.9.0 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.20.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дробление на чанки\n",
        "Функции (просто запустить все ячейк на исполнение, **ввести АПИ ключ**)"
      ],
      "metadata": {
        "id": "T-Gy173a_EoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (import)\n",
        "import gdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "SHTQ-kGZBvM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLj5oRE1Bv0t",
        "outputId": "5a3ff085-edf8-4391-ac26-829b644281d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, max_count, count_type, verbose=0):\n",
        "    # Функция для подсчета количества слов в фрагменте\n",
        "    def num_words(fragment):\n",
        "        return len(fragment.split())\n",
        "\n",
        "    # Функция для подсчета количества токенов в фрагменте\n",
        "    def num_tokens(fragment):\n",
        "        return num_tokens_from_string(fragment, \"cl100k_base\")\n",
        "\n",
        "    # Разделение текста на фрагменты, исключая теги HTML\n",
        "    fragments = [fragment.strip() for fragment in re.split(r\"<[^>]+>|[\\ufeff]\", text) if fragment.strip()]\n",
        "\n",
        "    # Выбор функции подсчета длины в зависимости от типа подсчета\n",
        "    length_function = num_words if count_type == \"words\" else num_tokens\n",
        "\n",
        "    # Создание объекта разделителя текста\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=max_count, chunk_overlap=0, length_function=length_function)\n",
        "\n",
        "    # Список для хранения фрагментов текста\n",
        "    source_chunks = []\n",
        "\n",
        "    # Обработка каждого фрагмента текста\n",
        "    for fragment in fragments:\n",
        "        if verbose:\n",
        "            # Вывод количества слов/токенов в фрагменте, если включен режим verbose\n",
        "            count = length_function(fragment)\n",
        "            print(f\"{count_type} in text fragment = {count}\\n{'-' * 5}\\n{fragment}\\n{'=' * 20}\")\n",
        "\n",
        "        # Разбиение фрагмента текста на части заданной длины с помощью разделителя\n",
        "        # и добавление каждой части в список source_chunks\n",
        "        #source_chunks.append(Document(page_content=fragment, metadata={}) for chunk in splitter.split_text(fragment))\n",
        "        source_chunks.extend(Document(page_content=chunk, metadata={}) for chunk in splitter.split_text(fragment))\n",
        "\n",
        "    # Возвращение списка фрагментов текста\n",
        "    return source_chunks\n",
        "\n",
        "\n",
        "def create_embedding(data, max_count, count_type):\n",
        "    def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "      \"\"\"Возвращает количество токенов в строке\"\"\"\n",
        "      encoding = tiktoken.get_encoding(encoding_name)\n",
        "      num_tokens = len(encoding.encode(string))\n",
        "      return num_tokens\n",
        "\n",
        "    source_chunks = []\n",
        "\n",
        "    source_chunks = split_text(text=data, max_count=max_count, count_type=count_type, verbose=0)\n",
        "\n",
        "    # Создание индексов документа\n",
        "    search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(), )\n",
        "\n",
        "    count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]), \"cl100k_base\")\n",
        "    print('\\n ===========================================: ')\n",
        "    print('Количество токенов в документе :', count_token)\n",
        "    print('ЦЕНА запроса:', 0.0004*(count_token/1000), ' $')\n",
        "    return search_index\n",
        "\n",
        "def load_search_indexes(url: str, max_count, count_type) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "    return create_embedding(text, max_count=max_count, count_type=count_type)"
      ],
      "metadata": {
        "id": "5fHFgXVjD8Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
        "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model)\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
        "        num_tokens = 0\n",
        "        for message in messages:\n",
        "            num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "            for key, value in message.items():\n",
        "                num_tokens += len(encoding.encode(value))\n",
        "                if key == \"name\":  # if there's a name, the role is omitted\n",
        "                    num_tokens += -1  # role is always required and always 1 token\n",
        "        num_tokens += 2  # every reply is primed with <im_start>assistant\n",
        "        return num_tokens\n",
        "    else:\n",
        "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")\n",
        "\n",
        "def insert_newlines(text: str, max_len: int = 170) -> str:\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + \" \" + word) > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += \" \" + word\n",
        "    lines.append(current_line)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def answer_index(system, topic, search_index, temp = 0, verbose = 0, top_similar_documents = 3):\n",
        "\n",
        "    #Выборка документов по схожести с вопросом\n",
        "    docs = search_index.similarity_search(topic, k=top_similar_documents)\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\nОтрывок документа №{i+1}\\n=====================' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "    if (verbose): print('message_content :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": system + f\"{message_content}\"},\n",
        "      {\"role\": \"user\", \"content\": topic}\n",
        "      ]\n",
        "\n",
        "    # example token count from the function defined above\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print(f\"{num_tokens_from_messages(messages, 'gpt-3.5-turbo-0613')} токенов использовано на вопрос\")\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=messages,\n",
        "    temperature=temp\n",
        "    )\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print(f'{completion[\"usage\"][\"total_tokens\"]} токенов использовано всего (вопрос-ответ).')\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print('ЦЕНА запроса с ответом :', 0.002*(completion[\"usage\"][\"total_tokens\"]/1000), ' $')\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    print('ОТВЕТ : \\n', insert_newlines(completion.choices[0].message.content))\n",
        "\n",
        "    # return completion"
      ],
      "metadata": {
        "id": "gHyfkhuTD_mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_document_text(url: str) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "retgCvPSEAZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_count = 2400            # максимальное кол-во символов в чанке\n",
        "count_type = \"words\"\n",
        "top_similar_documents = 3"
      ],
      "metadata": {
        "id": "MVgAI5qiECk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## загрузка доков и Ответ\n",
        "**Промпт - V9_test-questions_Eng_v.1**"
      ],
      "metadata": {
        "id": "i21-5Vxvl5qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Документ \"Тестовая БЗ - V9_test-questions_Eng_v.1\"\n",
        "kia_index = load_search_indexes('https://docs.google.com/document/d/1lmISV8QJ9djf9UwbFdBA3IvjtJZc5DYeaNAYWmjxIJc', max_count = max_count, count_type=count_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3VM20BjEH7T",
        "outputId": "c1f4d505-a0ff-4ebb-dabd-a301d9a9846d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===========================================: \n",
            "Количество токенов в документе : 2019\n",
            "ЦЕНА запроса: 0.0008076000000000001  $\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Промпт для Ответов модели - \"KIA Neural Prompt v.1 (400 т)\"\n",
        "\n",
        "kia_promt = load_document_text('https://docs.google.com/document/d/1tjjJQ0s0qKSdmg2Yd69NXX4_RGWLr0up')"
      ],
      "metadata": {
        "id": "vQ-1gsFWEPNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем ответы на 10 тестовых вопросов - вопросы пишем \"ручками\" в соответствующий параметр answer_index()\n",
        "\n",
        "ans = answer_index(\n",
        "    kia_promt,\n",
        "# Пишем текст вопроса вместо ************************ !!!\n",
        "    'Какие скидки или специальные предложения доступны для покупки Kia Picanto?',\n",
        "    kia_index,\n",
        "    verbose = 1,\n",
        "    top_similar_documents = top_similar_documents\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry5oldDwEc29",
        "outputId": "d2071a3a-4329-4d03-bd84-6ce0017ce136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===========================================: \n",
            "message_content :\n",
            " ======================================== \n",
            " \n",
            "Отрывок документа №1\n",
            "=====================Kia Picanto\r\n",
            "Options\r\n",
            "Picanto variants 5 available configurations\r\n",
            "Equipment 1 - Classic from 1,334,900 ₽\r\n",
            "Engine and transmission\r\n",
            "1.0 MPI / 67 hp / Petrol / Manual / Front Wheel Drive\r\n",
            "1.0 MPI / 67 hp / Petrol / Automatic / Front Wheel Drive\r\n",
            "Main options\r\n",
            "Rear seats with 60:40 folding backrests\r\n",
            "Steel wheels 14\" with decorative hubcaps and tires 175/65 R14\r\n",
            "Tire Pressure Monitoring System (TPMS)\r\n",
            "Electronic Stability Control (ESC)\r\n",
            "Front airbags\r\n",
            "Light sensor\r\n",
            "Heated windshield washer nozzles\r\n",
            "Audio system with 2 speakers\r\n",
            "Audio system with 4 speakers\r\n",
            "Learn more at https://www.kia.ru/models/picanto/options/\r\n",
            "Configuration 2 - Comfort from 1,409,900 ₽\r\n",
            "Engine and transmission\r\n",
            "1.0 MPI / 67 hp / Petrol / Manual / Front Wheel Drive\r\n",
            "1.0 MPI / 67 hp / Petrol / Automatic / Front Wheel Drive\r\n",
            "Main options\r\n",
            "Steel wheels 14\" with decorative hubcaps and tires 175/65 R14\r\n",
            "Heated front seats\r\n",
            "Heated steering wheel\r\n",
            "Electronic Stability Control (ESC)\r\n",
            "Audio system with 4 speakers\r\n",
            "Heated windshield washer nozzles\r\n",
            "Electrically adjustable and heated side mirrors\r\n",
            "Learn more at https://www.kia.ru/models/picanto/options/\r\n",
            "Equipment 3 - Luxe from 1,524,900 ₽\r\n",
            "Engine and transmission\r\n",
            "1.0 MPI / 67 hp / Petrol / Automatic / Front Wheel Drive\r\n",
            "Main options\r\n",
            "Alloy wheels 14'' with tires 175/65 R14\r\n",
            "LED taillights\r\n",
            "Front side airbags and curtain airbags\r\n",
            "Multimedia 8'' with 6 speakers, Apple Carplay and Android Auto support\r\n",
            "Bluetooth for connecting mobile devices\r\n",
            "Rear view camera\r\n",
            "Read more at https://www.kia.ru/models/picanto/options/\r\n",
            "Configuration 4 - Style from 1,564,900 ₽\r\n",
            "Engine and transmission\r\n",
            "1.0 MPI / 67 hp / Petrol / Automatic / Front Wheel Drive\r\n",
            "Main options\r\n",
            "Alloy wheels 15'' with tires 185/55 R15\r\n",
            "Climate control\r\n",
            "Multimedia 8'' with 6 speakers, Apple Carplay and Android Auto support\r\n",
            "Bluetooth for connecting mobile devices\r\n",
            "Rear view camera\r\n",
            "Learn more at https://www.kia.ru/models/picanto/options/\r\n",
            "Configuration 5 - GT Line from 1,624,900 ₽\r\n",
            "Engine and transmission\r\n",
            "1.0 MPI / 67 hp / Petrol / Automatic / Front Wheel Drive\r\n",
            "Main options\r\n",
            "Blind spot warning (BCW) system\r\n",
            "Smart Key keyless entry system and push-button engine start\r\n",
            "Supervision dashboard with 4.2'' color display\r\n",
            "Cruise control with speed limiter\r\n",
            "Multimedia 8'' with 6 speakers, Apple Carplay and Android Auto support\r\n",
            "Bluetooth for connecting mobile devices\r\n",
            "Alloy wheels 16'' with tires 195/45 R16\r\n",
            "Read more at https://www.kia.ru/models/picanto/options/  \n",
            "Отрывок документа №2\n",
            "=====================Kia Picanto\r\n",
            "You're looking at a fashionable car ideal for city streets and highways. Bold design, thoughtful interior and advanced safety technologies embody a car that can draw the eye and delight wherever you go. https://clck.ru/35PhHg\r\n",
            "GT Line\r\n",
            "For the most vivid emotions\r\n",
            "You'll hardly be able to contain your feelings when you see the Kia Picanto GT Line. Dynamic lines, striking front bumper, signature grille with bold surrounds, LED daytime running lights, shaped rear bumper. Rest assured: the GT Line is true style and true passion.\r\n",
            "Projector headlights with daytime running lights\r\n",
            "Rear combined LED rear lights\r\n",
            "Projector fog lights\r\n",
            "Chrome door handles\r\n",
            "Comfort\r\n",
            "Style and comfort\r\n",
            "The Kia Picanto is so well thought out that its compact dimensions make for a spacious and comfortable cabin. What's more, there's plenty of space for luggage. Add to that nice and useful features like heated steering wheel and heated front seats and you'll want to hit the road.\r\n",
            "Heated steering wheel. A real pleasure in cold weather. Now there is no need to be behind the wheel with gloves in winter. https://clck.ru/35PhRR\r\n",
            "Heated front seats. Heated front seats will make your ride more enjoyable in cold weather. https://clck.ru/35PhSE\r\n",
            "Automatic temperature control. Enjoy comfort with automatic temperature control. Simply set the desired temperature and the system will monitor and automatically maintain it until you change the settings. https://clck.ru/35PhSh\r\n",
            "Electric power steering with tilt steering function (MDPS). Electric power steering makes maneuvering easier, and the tilt steering column helps you get in and out of the vehicle. https://clck.ru/35PhTK\r\n",
            "Smart Key keyless entry system and push-button engine start. The Smart Key remote control allows you to unlock or lock the doors without a key, and the engine can be started by simply pressing a button in the car's interior. https://clck.ru/35PhTx\r\n",
            "Automatic light control. Set the paddle ring to the \"auto\" position and the front and rear lights will turn on or off depending on the light outside. https://clck.ru/35PhUd\r\n",
            "Multimedia\r\n",
            "Always in touch. Always smart\r\n",
            "Living in the present means always being in the know. That's why Kia Picanto offers smart information and entertainment solutions. You stay connected 24 hours a day with convenient smartphone connectivity via Bluetooth, while useful features such as Android Auto and Apple CarPlay allow you to get the most out of your car.\r\n",
            "8-inch audio system screen. The stylish multimedia system keeps you informed of trip status and entertained on the road. https://clck.ru/35PjPr\r\n",
            "New 4.2\" color 4.2\" digital Supervision dashboard. All the information you need about vehicle status and driving aspects appears on the bright screen and keeps you informed. https://clck.ru/35PjQ9\r\n",
            "Android Auto / Apple CarPlay. Use all the functions of your smartphones in your Kia Picanto while driving. All versions with an 8-inch display support Android Auto and Apple CarPlay. https://clck.ru/35PjQV\r\n",
            "USB port. Connect audio players and mobile devices using the USB port. https://clck.ru/35PjQi  \n",
            "Отрывок документа №3\n",
            "=====================Kia Picanto\r\n",
            "Capacity\r\n",
            "More wish fulfillment\r\n",
            "If you love adventure, the Kia Picanto is the car for you. With a spacious interior, comfortably folding rear seats and a generous 255 liters of luggage space that converts to an incredible 1,010 liters when the rear row is folded down, you're ready for both everyday driving and long journeys.\r\n",
            "Rear seats that fold down to a 60:40 ratio. Take everything you need on the road. You can easily fit your luggage in the cabin thanks to the 60:40 folding rear row seats. https://clck.ru/35Pjiz\r\n",
            "Two-level luggage compartment. The luggage compartment shelf forms a level floor with the rear row seats folded down, leaving room below for long items. https://clck.ru/35PjjN\r\n",
            "Double shelf for small items. The dual-level shelf located under the climate system allows you to conveniently place cosmetics, audio devices and other small things. https://clck.ru/35PjmC\r\n",
            "Front cup holders. Keep your drinks close at hand in the cup holders at the front of the console. And if you need more space, they fold down at the touch of a button. https://clck.ru/35PjmW\r\n",
            "Safety\r\n",
            "Safety first\r\n",
            "Rear parking assist system. If you are reversing out of a parking lot or garage, RCCW will scan the area behind your vehicle using radar and alert you with an audible warning of vehicles approaching you from the side.\r\n",
            "Blind Spot Warning (BCW). BCW will warn you of a vehicle in the next lane or approaching you from behind, which it detects using radar.\r\n",
            "Rearview Camera with Dynamic Guides. When you reverse into a parking space, the waterproof rear camera projects an image on the 8-inch display, along with dynamic directional indicators to show your direction of travel.\r\n",
            "Hill Start Assist System (HSAS). The system prevents you from rolling backwards when you start uphill. When you move your foot from the brake to the accelerator pedal, the system automatically applies the brakes.\r\n",
            "Electronic Stability Control (ESC). ESC provides optimum braking performance and directional stability by automatically distributing braking force to each wheel based on an assessment of engine torque and driving conditions.\r\n",
            "TPMS (tire pressure monitoring system). If a tire needs to be inflated, TPMS will alert you with an icon on the instrument panel.\r\n",
            "Absolute confidence\r\n",
            "Advanced High Strength Steel and Hot-Formed Steel (AHSS). The Kia Picanto body is 44% Advanced High Strength Steel (AHSS), with hot-formed steel components used in the main stress zones. This significantly increases body stiffness and average tensile strength, improving interior protection and vehicle dynamic performance. https://clck.ru/35PkCQ\r\n",
            "Airbags. To ensure safety and reduce the chance of injury in the event of a collision, the Kia Picanto is equipped with driver and front passenger airbags, two front side airbags and two side curtain airbags. https://clck.ru/35PkCz\r\n",
            "Engine\r\n",
            "Efficient Engines\r\n",
            "You can choose from two reliable gasoline engines with high efficiency and low fuel consumption. Each is ideal for city driving and capable of exceeding your expectations on the highway.\r\n",
            "Engine power 67hp\r\n",
            "Maximum torque 95.2 n.m.\r\n",
            "Acceleration from 0 to 100 km/h with (minimum value for this engine) 14.1 s\n",
            "\n",
            "\n",
            " ===========================================: \n",
            "2502 токенов использовано на вопрос\n",
            "\n",
            " ===========================================: \n",
            "2839 токенов использовано всего (вопрос-ответ).\n",
            "\n",
            " ===========================================: \n",
            "ЦЕНА запроса с ответом : 0.005678  $\n",
            "\n",
            " ===========================================: \n",
            "ОТВЕТ : \n",
            "  На данный момент у нас есть несколько специальных предложений для покупки Kia Picanto. Вот некоторые из них: 1. Финансовая программа \"Trade-in\". При сдаче вашего старого\n",
            " автомобиля в зачет на покупку нового Kia Picanto вы можете получить дополнительную скидку или выгодные условия кредита. 2. Программа лояльности для постоянных клиентов.\n",
            " Если вы уже являетесь владельцем автомобиля Kia, вы можете получить специальные условия на покупку нового Kia Picanto. 3. Специальные цены на определенные комплектации\n",
            " Kia Picanto. Мы предлагаем сниженные цены на некоторые модели и комплектации автомобиля. 4. Беспроцентный кредит. В рамках этой программы вы можете приобрести Kia\n",
            " Picanto в кредит без процентов на определенный период времени. Пожалуйста, обратитесь к вашему ближайшему дилеру Kia для получения более подробной информации о текущих\n",
            " специальных предложениях и скидках.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (финиш)"
      ],
      "metadata": {
        "id": "NAYY_z_3oC0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) Проверка ответов с помощью Chat GPT\n",
        "БЗ - **V9_test-questions_Eng_v.1**"
      ],
      "metadata": {
        "id": "wZ5l6vu7Pujy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install  tiktoken==0.4.0  langchain==0.0.231 openai==0.27.8 chromadb gspread oauth2client nltk pydantic==1.10.8 faiss-cpu==1.7.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTmoqrtOEef8",
        "outputId": "8bfe36d2-13b8-4c50-fddb-f2b3f44bb7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: langchain==0.0.231 in /usr/local/lib/python3.10/dist-packages (0.0.231)\n",
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.14)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.10/dist-packages (1.10.8)\n",
            "Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (0.5.14)\n",
            "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (0.0.20)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.2.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.103.2)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.23.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.2)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.14.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (0.9.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.231) (3.0.0)\n",
            "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.17.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дробление на чанки\n",
        "Функции (просто запустить все ячейк на исполнение, **ввести АПИ ключ**)"
      ],
      "metadata": {
        "id": "GkIXqnDOPukN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (import)\n",
        "import gdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "U-BYIotXFqBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, max_count, count_type, verbose=0):\n",
        "    # Функция для подсчета количества слов в фрагменте\n",
        "    def num_words(fragment):\n",
        "        return len(fragment.split())\n",
        "\n",
        "    # Функция для подсчета количества токенов в фрагменте\n",
        "    def num_tokens(fragment):\n",
        "        return num_tokens_from_string(fragment, \"cl100k_base\")\n",
        "\n",
        "    # Разделение текста на фрагменты, исключая теги HTML\n",
        "    fragments = [fragment.strip() for fragment in re.split(r\"<[^>]+>|[\\ufeff]\", text) if fragment.strip()]\n",
        "\n",
        "    # Выбор функции подсчета длины в зависимости от типа подсчета\n",
        "    length_function = num_words if count_type == \"words\" else num_tokens\n",
        "\n",
        "    # Создание объекта разделителя текста\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=max_count, chunk_overlap=0, length_function=length_function)\n",
        "\n",
        "    # Список для хранения фрагментов текста\n",
        "    source_chunks = []\n",
        "\n",
        "    # Обработка каждого фрагмента текста\n",
        "    for fragment in fragments:\n",
        "        if verbose:\n",
        "            # Вывод количества слов/токенов в фрагменте, если включен режим verbose\n",
        "            count = length_function(fragment)\n",
        "            print(f\"{count_type} in text fragment = {count}\\n{'-' * 5}\\n{fragment}\\n{'=' * 20}\")\n",
        "\n",
        "        # Разбиение фрагмента текста на части заданной длины с помощью разделителя\n",
        "        # и добавление каждой части в список source_chunks\n",
        "        #source_chunks.append(Document(page_content=fragment, metadata={}) for chunk in splitter.split_text(fragment))\n",
        "        source_chunks.extend(Document(page_content=chunk, metadata={}) for chunk in splitter.split_text(fragment))\n",
        "\n",
        "    # Возвращение списка фрагментов текста\n",
        "    return source_chunks\n",
        "\n",
        "\n",
        "def create_embedding(data, max_count, count_type):\n",
        "    def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "      \"\"\"Возвращает количество токенов в строке\"\"\"\n",
        "      encoding = tiktoken.get_encoding(encoding_name)\n",
        "      num_tokens = len(encoding.encode(string))\n",
        "      return num_tokens\n",
        "\n",
        "    source_chunks = []\n",
        "\n",
        "    source_chunks = split_text(text=data, max_count=max_count, count_type=count_type, verbose=0)\n",
        "\n",
        "    # Создание индексов документа\n",
        "    search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(), )\n",
        "\n",
        "    count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]), \"cl100k_base\")\n",
        "    print('\\n ===========================================: ')\n",
        "    print('Количество токенов в документе :', count_token)\n",
        "    print('ЦЕНА запроса:', 0.0004*(count_token/1000), ' $')\n",
        "    return search_index\n",
        "\n",
        "def load_search_indexes(url: str, max_count, count_type) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "    return create_embedding(text, max_count=max_count, count_type=count_type)"
      ],
      "metadata": {
        "id": "AqzXEJp0Fp-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
        "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model)\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
        "        num_tokens = 0\n",
        "        for message in messages:\n",
        "            num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "            for key, value in message.items():\n",
        "                num_tokens += len(encoding.encode(value))\n",
        "                if key == \"name\":  # if there's a name, the role is omitted\n",
        "                    num_tokens += -1  # role is always required and always 1 token\n",
        "        num_tokens += 2  # every reply is primed with <im_start>assistant\n",
        "        return num_tokens\n",
        "    else:\n",
        "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")\n",
        "\n",
        "def insert_newlines(text: str, max_len: int = 170) -> str:\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + \" \" + word) > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += \" \" + word\n",
        "    lines.append(current_line)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def answer_index(system, topic, search_index, temp = 0, verbose = 0, top_similar_documents = 3):\n",
        "\n",
        "    #Выборка документов по схожести с вопросом\n",
        "    docs = search_index.similarity_search(topic, k=top_similar_documents)\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\nОтрывок документа №{i+1}\\n=====================' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "    if (verbose): print('message_content :\\n ======================================== \\n', message_content)\n",
        "\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": system + f\"{message_content}\"},\n",
        "      {\"role\": \"user\", \"content\": topic}\n",
        "      ]\n",
        "\n",
        "    # example token count from the function defined above\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print(f\"{num_tokens_from_messages(messages, 'gpt-3.5-turbo-0613')} токенов использовано на вопрос\")\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=messages,\n",
        "    temperature=temp\n",
        "    )\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print(f'{completion[\"usage\"][\"total_tokens\"]} токенов использовано всего (вопрос-ответ).')\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    if (verbose): print('ЦЕНА запроса с ответом :', 0.002*(completion[\"usage\"][\"total_tokens\"]/1000), ' $')\n",
        "    if (verbose): print('\\n ===========================================: ')\n",
        "    print('ОТВЕТ : \\n', insert_newlines(completion.choices[0].message.content))\n",
        "\n",
        "    # return completion"
      ],
      "metadata": {
        "id": "dtNbc5o0Fp77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_document_text(url: str) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "by0nR1YKFpvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_count = 2400            # максимальное кол-во символов в чанке\n",
        "count_type = \"words\"\n",
        "top_similar_documents = 3"
      ],
      "metadata": {
        "id": "1Vpze6G5GBSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## загрузка доков и Оценка\n",
        "**Промпт: \"Промпт - Проверка Ответов = Eng (v.1) 511 т\"**"
      ],
      "metadata": {
        "id": "FiX5ohJVPukS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Документ \"Тестовая БЗ - KB_Picanto_test-questions_Eng_v.1\"\n",
        "kia_index = load_search_indexes('https://docs.google.com/document/d/1lmISV8QJ9djf9UwbFdBA3IvjtJZc5DYeaNAYWmjxIJc', max_count = max_count, count_type=count_type)"
      ],
      "metadata": {
        "id": "KjpNkVNiGHb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Промпт для ПРОВЕРКИ Ответов - \"Промпт - Проверка Ответов = Eng (v.1) 511 т\"\n",
        "\n",
        "kia_promt = load_document_text('https://docs.google.com/document/d/1ruT1--vEtCM7B2xVBHuMpBNfGFb2Q3nbU2wiKdFwEic')"
      ],
      "metadata": {
        "id": "G8EweA2QGIaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем ответы на 10 тестовых вопросов - вопросы пишем \"ручками\" в соответствующий параметр answer_index()\n",
        "\n",
        "ans = answer_index(\n",
        "    kia_promt,\n",
        "# Пишем текст Вопроса и Ответа (из п. (2) ) между 3-х кавычек !!!\n",
        "    '''\n",
        "***Вопрос: Какие скидки или специальные предложения доступны для покупки Kia Picanto?***.\n",
        "**Ответ: На данный момент у нас есть несколько специальных предложений для покупки Kia Picanto. Вот некоторые из них: 1. Финансовая программа \"Trade-in\". При сдаче вашего старого\n",
        " автомобиля в зачет на покупку нового Kia Picanto вы можете получить дополнительную скидку или выгодные условия кредита. 2. Программа лояльности для постоянных клиентов.\n",
        " Если вы уже являетесь владельцем автомобиля Kia, вы можете получить специальные условия на покупку нового Kia Picanto. 3. Специальные цены на определенные комплектации\n",
        " Kia Picanto. Мы предлагаем сниженные цены на некоторые модели и комплектации автомобиля. 4. Беспроцентный кредит. В рамках этой программы вы можете приобрести Kia\n",
        " Picanto в кредит без процентов на определенный период времени. Пожалуйста, обратитесь к вашему ближайшему дилеру Kia для получения более подробной информации о текущих\n",
        " специальных предложениях и скидках.**\n",
        "    ''',\n",
        "    kia_index,\n",
        "    verbose = 1,\n",
        "    top_similar_documents = top_similar_documents\n",
        ")"
      ],
      "metadata": {
        "id": "6TFn4OFtGLh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (финиш)"
      ],
      "metadata": {
        "id": "X4MyMLLdPukU"
      }
    }
  ]
}