{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ТЕСТИРОВАНИЕ B20 RELEASE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kbqMeB_pSLD",
        "outputId": "19275dfd-a2b6-4fac-cf3c-2a8d53322fb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/KIA_TEST/FAISS_KIA_B20\n",
        "!mkdir -p /content/drive/MyDrive/KIA_TEST/FAISS_KIA_B20\n",
        "!git clone -b faiss/B20 https://github.com/musicnova/KIA-GPT0.git FAISS_KIA_B20\n",
        "!cp -r /content/FAISS_KIA_B20/knowledge/faiss_router /content/drive/MyDrive/KIA_TEST/FAISS_KIA_B20/faiss_router\n",
        "!rm -r /content/FAISS_KIA_B20\n"
      ],
      "metadata": {
        "id": "3ijs5xXopVdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37aad4a-f676-4ac8-834d-4512d03c4c4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FAISS_KIA_B20'...\n",
            "remote: Enumerating objects: 2118, done.\u001b[K\n",
            "remote: Counting objects: 100% (531/531), done.\u001b[K\n",
            "remote: Compressing objects: 100% (199/199), done.\u001b[K\n",
            "remote: Total 2118 (delta 389), reused 420 (delta 332), pack-reused 1587\u001b[K\n",
            "Receiving objects: 100% (2118/2118), 42.30 MiB | 33.04 MiB/s, done.\n",
            "Resolving deltas: 100% (1233/1233), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf faiss_routing\n",
        "!cp -r /content/drive/MyDrive/KIA_TEST/FAISS_KIA_B20/faiss_router faiss_routing"
      ],
      "metadata": {
        "id": "rPgxTCh4p0o7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsFGkXMMwcX3"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nH2KyinoxhE",
        "outputId": "45a69eae-b830-48ed-b023-b2ad00b2c5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken==0.4.0\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.0.231\n",
            "  Downloading langchain-0.0.231-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu==1.7.4\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting pydantic==1.10.8\n",
            "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (3.8.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.231)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain==0.0.231)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.231)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.231) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-cpu, pydantic, mypy-extensions, marshmallow, typing-inspect, tiktoken, openapi-schema-pydantic, langchainplus-sdk, openai, dataclasses-json, langchain\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.5.14 faiss-cpu-1.7.4 langchain-0.0.231 langchainplus-sdk-0.0.20 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 pydantic-1.10.8 tiktoken-0.4.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip  install  tiktoken==0.4.0  langchain==0.0.231 openai==0.27.8 faiss-cpu==1.7.4 gspread oauth2client nltk pydantic==1.10.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wNTJkb02qexK"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "#database\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#from langchain.document_loaders import TextLoader\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "import ipywidgets as widgets\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "def clear_screen():\n",
        "    system_platform = platform.system()  # определить операционную систему\n",
        "    if system_platform == \"Windows\":\n",
        "        os.system('cls')\n",
        "    else:\n",
        "        os.system('clear')"
      ],
      "metadata": {
        "id": "BAWhNQ0K7x6k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Lh42jUHVy3fq"
      },
      "outputs": [],
      "source": [
        "MODEL_GPT_3_5_TURBO_16K = ['gpt-3.5-turbo-16k', 0.003, 0.004]\n",
        "MODEL_GPT_3_5_TURBO = ['gpt-3.5-turbo', 0.0015, 0.002]  # 4,097 tokens\n",
        "MODEL_GPT_3_5_TURBO_INSTRUCT = ['gpt-3.5-turbo-instruct', 0.0015, 0.002]  # 4,097 tokens\n",
        "MODEL_GPT_4 = ['gpt-4', 0.03, 0.06]  # 8,192 tokens\n",
        "SELECT_MODEL_GPT = MODEL_GPT_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jSdHAWANqs7C"
      },
      "outputs": [],
      "source": [
        "# openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "# openai.api_key = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eAafR4VwqtFS"
      },
      "outputs": [],
      "source": [
        "def insert_newlines(textstr: str, max_len: int = 170) -> str:\n",
        "    words = textstr.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line + \" \" + word) > max_len:\n",
        "            lines.append(current_line)\n",
        "            current_line = \"\"\n",
        "        current_line += \" \" + word\n",
        "    lines.append(current_line)\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1YFsrIhi4Yct"
      },
      "outputs": [],
      "source": [
        "# функция для загрузки документа по ссылке из гугл драйв\n",
        "def load_document_text(url: str) -> str:\n",
        "    # Extract the document ID from the URL\n",
        "    match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "    if match_ is None:\n",
        "        raise ValueError('Invalid Google Docs URL')\n",
        "    doc_id = match_.group(1)\n",
        "\n",
        "    # Download the document as plain text\n",
        "    response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l6EU0C7uUFp"
      },
      "source": [
        "## Собрать новую базу FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YnSehGphiewU"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "import re\n",
        "\n",
        "def load_file_knowledge(file_path: str) -> str:\n",
        "    # Чтение текстового файла\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    headers_to_split_on = [\n",
        "        (\"#\", \"router\"),\n",
        "        (\"##\", \"Header2\"),\n",
        "        (\"###\", \"Header3\"),\n",
        "        (\"####\", \"Header4\"),\n",
        "    ]\n",
        "\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "    md_header_splits = markdown_splitter.split_text(text)\n",
        "\n",
        "    # Предполагается, что FAISS и OpenAIEmbeddings были импортированы или определены где-то выше\n",
        "    vectordateBase = FAISS.from_documents(md_header_splits, OpenAIEmbeddings())\n",
        "\n",
        "    return vectordateBase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9CrXhbfVqtP_"
      },
      "outputs": [],
      "source": [
        "## models_knowledge_base = load_file_knowledge('models.md')\n",
        "## technology_knowledge_base = load_file_knowledge('technology.md')\n",
        "## parts_knowledge_base = load_file_knowledge('parts.md')\n",
        "## oils_knowledge_base = load_file_knowledge('oils.md')\n",
        "## tech_knowledge_base = load_file_knowledge('tech.md')\n",
        "## accessories_knowledge_base = load_file_knowledge('accessories.md')\n",
        "## warranty_knowledge_base = load_file_knowledge('warranty.md')\n",
        "## service_knowledge_base = load_file_knowledge('service.md')\n",
        "## sales_knowledge_base = load_file_knowledge('sales.md')\n",
        "## apps_knowledge_base = load_file_knowledge('apps.md')\n",
        "## promotions_knowledge_base = load_file_knowledge('promotions.md')\n",
        "## #none_knowledge_base = load_file_knowledge('none.md')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3fiDyYSqvuA"
      },
      "source": [
        "## Проверка чанков **БЕЗ** сбора нового файла FAISS **БЕЗ** обращения к OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install  tiktoken==0.4.0  langchain==0.0.231 openai==0.27.8 faiss-cpu==1.7.4 gspread oauth2client nltk pydantic==1.10.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_hi8kkfq6TV",
        "outputId": "0d5e5608-fa25-4e45-c6f8-ddf678746e6d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: langchain==0.0.231 in /usr/local/lib/python3.10/dist-packages (0.0.231)\n",
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.10/dist-packages (1.10.8)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (3.8.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (0.5.14)\n",
            "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (0.0.20)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (1.2.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.231) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.231) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (0.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.231) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.231) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "#database\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#from langchain.document_loaders import TextLoader\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "import ipywidgets as widgets\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "\n",
        "HISTORY = []"
      ],
      "metadata": {
        "id": "upyg9fjgq-sW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_GPT_3_5_TURBO_16K = ['gpt-3.5-turbo-16k', 0.003, 0.004]\n",
        "MODEL_GPT_3_5_TURBO = ['gpt-3.5-turbo', 0.0015, 0.002]  # 4,097 tokens\n",
        "MODEL_GPT_4 = ['gpt-4', 0.03, 0.06]  # 8,192 tokens\n",
        "SELECT_MODEL_GPT = MODEL_GPT_3_5_TURBO_16K"
      ],
      "metadata": {
        "id": "kzkg5bierBx_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qd6-_EUrDby",
        "outputId": "271c6bcb-f6d2-48df-82db-bd5b1817d22e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем векторный файл базы знаний! В коллаб надо в папку faiss загрузить 2 файла\n",
        "\n",
        "models_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_models\", OpenAIEmbeddings())\n",
        "technology_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_technology\", OpenAIEmbeddings())\n",
        "parts_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_parts\", OpenAIEmbeddings())\n",
        "oils_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_oils\", OpenAIEmbeddings())\n",
        "tech_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_tech\", OpenAIEmbeddings())\n",
        "accessories_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_accessories\", OpenAIEmbeddings())\n",
        "warranty_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_warranty\", OpenAIEmbeddings())\n",
        "service_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_service\", OpenAIEmbeddings())\n",
        "sales_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_sales\", OpenAIEmbeddings())\n",
        "apps_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_apps\", OpenAIEmbeddings())\n",
        "promotions_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_promotions\", OpenAIEmbeddings())\n",
        "#none_knowledge_base = FAISS.load_local(\"faiss_routing/faiss_models\", OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "M1eAM1XfqxWg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "models_template = \"\"\"You are a very smart assistant for Kia. You know everything about KIA car models\n",
        "You are excellent at answering questions about Kia car models concisely and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "technology_template = \"\"\"You are a very smart assistant for KIA. You know everything about the technologies used in KIA cars.\n",
        "You are excellent at answering questions briefly and clearly about the technologies used in KIA cars.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "parts_template = \"\"\"You are a very smart assistant for KIA. You know all the information on spare parts for KIA cars.\n",
        "You are excellent at answering questions about spare parts for KIA cars briefly and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "oils_template = \"\"\"You are a very smart assistant for KIA. You know all the information on engine oils for KIA cars.\n",
        "You are excellent at answering questions about engine oils for KIA cars briefly and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "tech_template = \"\"\"You are a very smart assistant for KIA. You know everything about the maintenance of KIA cars.\n",
        "You are excellent at answering questions about KIA vehicle maintenance briefly and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "accessories_template = \"\"\"You are a very smart assistant for KIA. You know all the information about accessories for KIA cars.\n",
        "You are excellent at answering questions about accessories for KIA cars concisely and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "warranty_template = \"\"\"You are a very smart assistant for KIA. You know all the information about the warranty for KIA cars.\n",
        "You are excellent at answering questions about KIA vehicle warranties concisely and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "service_template = \"\"\"You are a very smart assistant for KIA. You know all the information about servicing KIA cars.\n",
        "You are excellent at answering questions about service for KIA vehicles briefly and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "sales_template = \"\"\"You are a very smart assistant for KIA. You know all the information about KIA car sales.\n",
        "You are excellent at answering questions about KIA car sales briefly and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "apps_template = \"\"\"You are a very smart assistant for KIA. You know all the information about KIA software.\n",
        "You are excellent at answering questions about KIA software briefly and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "promotion_template = \"\"\"You are a very smart assistant for KIA. You know everything about promotions of KIA company.\n",
        "You are excellent at answering questions about promotions of KIA company concisely and clearly.\n",
        "When you don't know the answer to a question, you admit that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"models\",\n",
        "        \"description\": \"Good for answering questions about models kia auto\",\n",
        "        \"prompt_template\": models_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"technology\",\n",
        "        \"description\": \"Good for answering questions about Kia technology.\",\n",
        "        \"prompt_template\": technology_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"parts\",\n",
        "        \"description\": \"Good for answering questions about Kia parts.\",\n",
        "        \"prompt_template\": parts_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"oils\",\n",
        "        \"description\": \"Good for answering questions about Kia engine oils.\",\n",
        "        \"prompt_template\": oils_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"tech\",\n",
        "        \"description\": \"Good for answering questions about technical problems with Kia vehicles.\",\n",
        "        \"prompt_template\": tech_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"accessories\",\n",
        "        \"description\": \"Good for answering questions about accessories used in Kia vehicles.\",\n",
        "        \"prompt_template\": accessories_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"warranty\",\n",
        "        \"description\": \"Good for answering questions about Kia vehicle warranties.\",\n",
        "        \"prompt_template\": warranty_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"service\",\n",
        "        \"description\": \"Good for answering Kia vehicle service questions.\",\n",
        "        \"prompt_template\": service_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"sales\",\n",
        "        \"description\": \"Good for answering Kia car sales questions.\",\n",
        "        \"prompt_template\": sales_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"apps\",\n",
        "        \"description\": \"Good for answering questions about using Kia software.\",\n",
        "        \"prompt_template\": apps_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"promotion\",\n",
        "        \"description\": \"Good for answering questions about Kia promotions.\",\n",
        "        \"prompt_template\": promotion_template,\n",
        "    },\n",
        "]\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "default_chain = ConversationChain(llm=llm, output_key=\"text\")\n",
        "\n",
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
        "\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)\n",
        "print(destinations_str)\n",
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "\n",
        "\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
        "\n",
        "\n",
        "\n",
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chains,\n",
        "    default_chain=default_chain,\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLhnEzASR7G8",
        "outputId": "d3383fae-2ab8-4406-e55e-2307e9a2d97e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models: Good for answering questions about models kia auto\n",
            "technology: Good for answering questions about Kia technology.\n",
            "parts: Good for answering questions about Kia parts.\n",
            "oils: Good for answering questions about Kia engine oils.\n",
            "tech: Good for answering questions about technical problems with Kia vehicles.\n",
            "accessories: Good for answering questions about accessories used in Kia vehicles.\n",
            "warranty: Good for answering questions about Kia vehicle warranties.\n",
            "service: Good for answering Kia vehicle service questions.\n",
            "sales: Good for answering Kia car sales questions.\n",
            "apps: Good for answering questions about using Kia software.\n",
            "promotion: Good for answering questions about Kia promotions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dsEKLyifvEto"
      },
      "outputs": [],
      "source": [
        "def _summarize_topic( dialog):\n",
        "        messages = [\n",
        "            {\"role\": \"system\",\n",
        "             \"content\": \"Ты - ассистент консультанта, основанный на AI. Ты умеешь профессионально суммаризировать присланные тебе диалоги консультанта и клиента. Твоя задача - суммаризировать диалог, который тебе пришел.\"},\n",
        "            {\"role\": \"user\",\n",
        "             \"content\": \"Суммаризируй следующий диалог консультанта и клиента: \" + \" \".join(dialog)}\n",
        "        ]\n",
        "\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=SELECT_MODEL_GPT[0],\n",
        "            messages=messages,\n",
        "            temperature=0.1,  # Используем более низкую температуру для более определенной суммаризации\n",
        "            max_tokens=1000  # Ограничиваем количество токенов для суммаризации\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "def answer_index(topic, temp=0.1, top_similar_documents=3):\n",
        "\n",
        "        router_result = router_chain.__call__({\"input\": topic})\n",
        "        chosen_route = router_result['destination']\n",
        "        next_inputs = router_result['next_inputs']\n",
        "        print(f\"Выбранный маршрут: {chosen_route}\")\n",
        "        print(f\"Следующие входные данные: {next_inputs}\")\n",
        "\n",
        "        unit_to_multiplier = {\n",
        "            'models':  models_knowledge_base,\n",
        "            'technology': technology_knowledge_base,\n",
        "            'parts':  parts_knowledge_base,\n",
        "            'oils': oils_knowledge_base,\n",
        "            'tech': tech_knowledge_base,\n",
        "            'accessories': accessories_knowledge_base,\n",
        "            'warranty': warranty_knowledge_base,\n",
        "            'service': service_knowledge_base,\n",
        "            'sales': sales_knowledge_base,\n",
        "            'apps': apps_knowledge_base,\n",
        "            'promotions': promotions_knowledge_base\n",
        "        }\n",
        "\n",
        "        summarize_text = ''\n",
        "        if len(HISTORY) > 0:\n",
        "            summarize_text = \"Вот краткий обзор предыдущего диалога: \" + _summarize_topic(\n",
        "                [q + ' ' + (a if a is not None else '') for q, a in HISTORY])\n",
        "            print(f'САММАРИ \\n=== {summarize_text} \\n')\n",
        "\n",
        "        # Добавляем явное разделение между историей диалога и текущим вопросом\n",
        "        input_text = summarize_text + \"\\n\\nТекущий вопрос: \" + topic\n",
        "\n",
        "        knowledge_base = unit_to_multiplier.get(chosen_route, None)\n",
        "        if knowledge_base is not None:\n",
        "            docs = knowledge_base.similarity_search_with_score(topic, k=top_similar_documents)\n",
        "        else:\n",
        "            return  insert_newlines('Вопрос не понятен!!!')\n",
        "\n",
        "\n",
        "        responses = []\n",
        "        for i, (doc, score) in enumerate(docs):\n",
        "            if score < 1: # ТУТ ТЫ МОЖЕШЬ УПРАВЛЯТЬ праметром Л2 для чанков. 0..1\n",
        "                content = doc.page_content\n",
        "                response = f'\\n=======Отрывок документа №{i + 1}=====\\n{content}\\n'\n",
        "                print(f'\\n=====================Отрывок документа №{i + 1}=====================\\n')\n",
        "                print(f'=== score = {score}  Metadata документа ------------ {doc.metadata}')\n",
        "                print(f'\\n{content}\\n')\n",
        "                responses.append(response)\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\",\n",
        "             \"content\": f\"Документ с информацией для ответа клиенту: {responses}\\n\\nВопрос клиента: \\n{input_text}\"}\n",
        "        ]\n",
        "\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=SELECT_MODEL_GPT[0],\n",
        "            messages=messages,\n",
        "            temperature=temp\n",
        "        )\n",
        "\n",
        "        answer = completion.choices[0].message.content\n",
        "\n",
        "        # Добавляем вопрос пользователя и ответ системы в историю\n",
        "        HISTORY.append((topic, answer if answer is not None else ''))\n",
        "\n",
        "        return  insert_newlines(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "g8N4WuC7qtKO"
      },
      "outputs": [],
      "source": [
        "def run_dialog():\n",
        "    import time\n",
        "    HISTORY = []\n",
        "    AUTO_HELLO=\"Иван. Мне 10 лет. У папы сломалась KIA RIO в стандартной комплектации.\"\n",
        "    topic = 'Приветствую, я нейро-помощник KIA. Подскажите, какая у Вас марка машины? Как я могу к Вам обращаться?'\n",
        "    print('\\nМенеджер: ', topic+'\\n\\n')\n",
        "    print('\\nКлиент: ', AUTO_HELLO+'\\n\\n')\n",
        "    user_question = AUTO_HELLO\n",
        "    answer = answer_index(user_question)\n",
        "    HISTORY.append((topic, answer if answer is not None else ''))\n",
        "    print('\\nМенеджер: ', 'Какая Вам требуется помощь?'+'\\n\\n')\n",
        "    while True:\n",
        "        user_question = input('\\nКлиент: ')\n",
        "        if ((user_question.lower() == 'stop') or (user_question.lower() == 'стоп')):\n",
        "            break\n",
        "        try:\n",
        "            answer = answer_index(user_question)\n",
        "        except:\n",
        "            time.sleep(1)\n",
        "            HISTORY = []\n",
        "            answer_index(None, None, None, knowledge_only_langchain, AUTO_HELLO)\n",
        "        print('\\nМенеджер: ', answer+'\\n\\n')\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YCBakZx6qtVM"
      },
      "outputs": [],
      "source": [
        "# Промпт моделей машин\n",
        "prompt = load_document_text ('https://docs.google.com/document/d/1i8HA7cX4Ut-tb9rf8wOgERU7lLe66xJYscizGtSSJl0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWY1AS2GvTN5",
        "outputId": "74833891-f542-421d-ee76-b922d9ba56af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Менеджер:  Приветствую, я нейро-помощник KIA. Подскажите, какая у Вас марка машины? Как я могу к Вам обращаться?\n",
            "\n",
            "\n",
            "\n",
            "Клиент:  Иван. Мне 10 лет. У папы сломалась KIA RIO в стандартной комплектации.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выбранный маршрут: service\n",
            "Следующие входные данные: {'input': 'Папа имеет проблему с KIA RIO в стандартной комплектации. Какой вид сервисной поддержки необходим?'}\n",
            "\n",
            "=====================Отрывок документа №1=====================\n",
            "\n",
            "=== score = 0.2921800911426544  Metadata документа ------------ {'router': 'service', 'Header2': 'Рекомендация обратиться в службу \"Помощь на дороге\" для проблем с Kia Рио'}\n",
            "\n",
            "В случае проблем с заводом автомобиля Киа Рио, рекомендуется обратиться в службу \"Помощь на дороге\" по номеру 8 800 301 08 80.\n",
            "\n",
            "\n",
            "=====================Отрывок документа №2=====================\n",
            "\n",
            "=== score = 0.3013317584991455  Metadata документа ------------ {'router': 'service', 'Header2': 'Проблема с коробкой передач и чеком на Kia Rio'}\n",
            "\n",
            "В случае проблем с коробкой передач и загоревшимся чеком на Киа Рио, необходимо обратиться в дилерский центр. Список официальных дилеров Kia доступен на сайте компании.\n",
            "\n",
            "\n",
            "=====================Отрывок документа №3=====================\n",
            "\n",
            "=== score = 0.30305224657058716  Metadata документа ------------ {'router': 'service', 'Header2': 'Отзыв автомобилей Kia Sorento 21 и 22 года из-за проблем с коробкой'}\n",
            "\n",
            "Информацию о том, что Kia отзывает автомобили Sorento 21 и 22 года из-за проблем с коробкой, можно проверить на сайте kia.ru. В случае отзывной компании, можно\n",
            "обратиться к дилеру за обслуживанием. В Калининграде это ДО-КАР, Московский пр-т, 207.\n",
            "\n",
            "\n",
            "Менеджер:  Какая Вам требуется помощь?\n",
            "\n",
            "\n",
            "\n",
            "Клиент: стоп\n"
          ]
        }
      ],
      "source": [
        "\n",
        "run_dialog()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}